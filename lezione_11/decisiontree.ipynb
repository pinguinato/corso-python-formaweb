{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, learn Decision Tree Classification, attribute selection measures, and how to build and optimize Decision Tree Classifier using Python Scikit-learn package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://www.datacamp.com/community/tutorials/decision-tree-classification-python](https://www.datacamp.com/community/tutorials/decision-tree-classification-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://medium.com/@randerson112358/build-your-own-artificial-neural-network-using-python-f37d16be06bf](https://medium.com/@randerson112358/build-your-own-artificial-neural-network-using-python-f37d16be06bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1545934190/1_r5ikdb.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1545934190/2_btay8n.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIMA\n",
    "\n",
    "The Pima are a group of Native Americans living in an area consisting of what is now central and southern Arizona. The Pima have the highest reported prevalence of diabetes of any population in the world, and have contributed to numerous scientific gains through their willingness to participate in the research process. Their involvement has led to significant findings with regard to the epidemiology, physiology, clinical assessment, and genetics of both type 2 diabetes and obesity. â€” [National Center for Biotechnology Information](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4418458/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/03/%22Pima_Indians_from_Arizona._Chief_Blue_Wing_and_family.%22_Department_of_Anthropology%2C_1904_World%27s_Fair.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://www.kaggle.com/uciml/pima-indians-diabetes-database](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "pima = pd.read_csv(\"datasets_228_482_diabetes.csv\", header=0, names=col_names)\n",
    "\n",
    "pima.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6926406926406926\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7705627705627706\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Slide di teoria](http://www-dimat.unipv.it/gualandi/programmazione2/slide_ann.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the shape (number of rows & columns)\n",
    "pima.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for duplicates and removing them\n",
    "pima.drop_duplicates(inplace = True)\n",
    "#Show the shape to see if any rows were dropped \n",
    "pima.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant    0\n",
       "glucose     0\n",
       "bp          0\n",
       "skin        0\n",
       "insulin     0\n",
       "bmi         0\n",
       "pedigree    0\n",
       "age         0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the number of missing (NAN, NaN, na) data for each column\n",
    "pima.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the data into an array\n",
    "dataset = pima.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the rows from the first eight columns of the dataset\n",
    "X = dataset[:,0:8] \n",
    "# Get all of the rows from the last column\n",
    "y = dataset[:,8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
       "        0.48333333],\n",
       "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
       "        0.16666667],\n",
       "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
       "        0.18333333],\n",
       "       ...,\n",
       "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
       "        0.15      ],\n",
       "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
       "        0.43333333],\n",
       "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
       "        0.03333333]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can start building the artificial neural network. The models architecture will contain three layers. The first layer will have 12 neurons and use the ReLu activation function, the second layer will have 15 neurons and use the ReLu activation function, and the third and final layer will use 1 neuron and the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=( 8 ,)),\n",
    "    Dense(15, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/1000\n",
      "491/491 [==============================] - 0s 254us/step - loss: 0.6868 - accuracy: 0.6069 - val_loss: 0.6855 - val_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6826 - accuracy: 0.6456 - val_loss: 0.6810 - val_accuracy: 0.6504\n",
      "Epoch 3/1000\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.6785 - accuracy: 0.6578 - val_loss: 0.6769 - val_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.6747 - accuracy: 0.6680 - val_loss: 0.6729 - val_accuracy: 0.6585\n",
      "Epoch 5/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.70 - 0s 81us/step - loss: 0.6711 - accuracy: 0.6721 - val_loss: 0.6694 - val_accuracy: 0.6423\n",
      "Epoch 6/1000\n",
      "491/491 [==============================] - 0s 100us/step - loss: 0.6680 - accuracy: 0.6680 - val_loss: 0.6661 - val_accuracy: 0.6423\n",
      "Epoch 7/1000\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.6651 - accuracy: 0.6599 - val_loss: 0.6632 - val_accuracy: 0.6585\n",
      "Epoch 8/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6626 - accuracy: 0.6497 - val_loss: 0.6607 - val_accuracy: 0.6585\n",
      "Epoch 9/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6604 - accuracy: 0.6497 - val_loss: 0.6585 - val_accuracy: 0.6585\n",
      "Epoch 10/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.6585 - accuracy: 0.6477 - val_loss: 0.6564 - val_accuracy: 0.6585\n",
      "Epoch 11/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6567 - accuracy: 0.6477 - val_loss: 0.6545 - val_accuracy: 0.6585\n",
      "Epoch 12/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.6551 - accuracy: 0.6477 - val_loss: 0.6530 - val_accuracy: 0.6504\n",
      "Epoch 13/1000\n",
      "491/491 [==============================] - 0s 108us/step - loss: 0.6535 - accuracy: 0.6477 - val_loss: 0.6517 - val_accuracy: 0.6504\n",
      "Epoch 14/1000\n",
      "491/491 [==============================] - 0s 104us/step - loss: 0.6523 - accuracy: 0.6477 - val_loss: 0.6505 - val_accuracy: 0.6504\n",
      "Epoch 15/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.6511 - accuracy: 0.6477 - val_loss: 0.6495 - val_accuracy: 0.6504\n",
      "Epoch 16/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6502 - accuracy: 0.6477 - val_loss: 0.6485 - val_accuracy: 0.6504\n",
      "Epoch 17/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6493 - accuracy: 0.6477 - val_loss: 0.6477 - val_accuracy: 0.6504\n",
      "Epoch 18/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6485 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
      "Epoch 19/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6478 - accuracy: 0.6477 - val_loss: 0.6463 - val_accuracy: 0.6504\n",
      "Epoch 20/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.6471 - accuracy: 0.6477 - val_loss: 0.6456 - val_accuracy: 0.6504\n",
      "Epoch 21/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6465 - accuracy: 0.6477 - val_loss: 0.6450 - val_accuracy: 0.6504\n",
      "Epoch 22/1000\n",
      "491/491 [==============================] - 0s 122us/step - loss: 0.6459 - accuracy: 0.6477 - val_loss: 0.6445 - val_accuracy: 0.6504\n",
      "Epoch 23/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6454 - accuracy: 0.6477 - val_loss: 0.6439 - val_accuracy: 0.6504\n",
      "Epoch 24/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.6449 - accuracy: 0.6477 - val_loss: 0.6434 - val_accuracy: 0.6504\n",
      "Epoch 25/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.6444 - accuracy: 0.6477 - val_loss: 0.6428 - val_accuracy: 0.6504\n",
      "Epoch 26/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6439 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.6504\n",
      "Epoch 27/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6434 - accuracy: 0.6477 - val_loss: 0.6419 - val_accuracy: 0.6504\n",
      "Epoch 28/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6429 - accuracy: 0.6477 - val_loss: 0.6415 - val_accuracy: 0.6504\n",
      "Epoch 29/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6425 - accuracy: 0.6477 - val_loss: 0.6411 - val_accuracy: 0.6504\n",
      "Epoch 30/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6422 - accuracy: 0.6477 - val_loss: 0.6407 - val_accuracy: 0.6504\n",
      "Epoch 31/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.6418 - accuracy: 0.6477 - val_loss: 0.6403 - val_accuracy: 0.6504\n",
      "Epoch 32/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.6414 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
      "Epoch 33/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6411 - accuracy: 0.6477 - val_loss: 0.6396 - val_accuracy: 0.6504\n",
      "Epoch 34/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6408 - accuracy: 0.6477 - val_loss: 0.6393 - val_accuracy: 0.6504\n",
      "Epoch 35/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.6404 - accuracy: 0.6477 - val_loss: 0.6389 - val_accuracy: 0.6504\n",
      "Epoch 36/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.6400 - accuracy: 0.6477 - val_loss: 0.6386 - val_accuracy: 0.6504\n",
      "Epoch 37/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6397 - accuracy: 0.6477 - val_loss: 0.6383 - val_accuracy: 0.6504\n",
      "Epoch 38/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6394 - accuracy: 0.6477 - val_loss: 0.6380 - val_accuracy: 0.6504\n",
      "Epoch 39/1000\n",
      "491/491 [==============================] - 0s 42us/step - loss: 0.6390 - accuracy: 0.6477 - val_loss: 0.6377 - val_accuracy: 0.6504\n",
      "Epoch 40/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6387 - accuracy: 0.6477 - val_loss: 0.6374 - val_accuracy: 0.6504\n",
      "Epoch 41/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.6384 - accuracy: 0.6477 - val_loss: 0.6371 - val_accuracy: 0.6504\n",
      "Epoch 42/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6381 - accuracy: 0.6477 - val_loss: 0.6368 - val_accuracy: 0.6504\n",
      "Epoch 43/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.6378 - accuracy: 0.6477 - val_loss: 0.6365 - val_accuracy: 0.6504\n",
      "Epoch 44/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6375 - accuracy: 0.6477 - val_loss: 0.6362 - val_accuracy: 0.6504\n",
      "Epoch 45/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.6372 - accuracy: 0.6477 - val_loss: 0.6359 - val_accuracy: 0.6504\n",
      "Epoch 46/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6369 - accuracy: 0.6477 - val_loss: 0.6356 - val_accuracy: 0.6504\n",
      "Epoch 47/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.6593 - accuracy: 0.57 - 0s 69us/step - loss: 0.6366 - accuracy: 0.6477 - val_loss: 0.6353 - val_accuracy: 0.6504\n",
      "Epoch 48/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.6363 - accuracy: 0.6477 - val_loss: 0.6350 - val_accuracy: 0.6504\n",
      "Epoch 49/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6347 - val_accuracy: 0.6504\n",
      "Epoch 50/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6356 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6504\n",
      "Epoch 51/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6353 - accuracy: 0.6477 - val_loss: 0.6341 - val_accuracy: 0.6504\n",
      "Epoch 52/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.6350 - accuracy: 0.6477 - val_loss: 0.6338 - val_accuracy: 0.6504\n",
      "Epoch 53/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6348 - accuracy: 0.6477 - val_loss: 0.6335 - val_accuracy: 0.6504\n",
      "Epoch 54/1000\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.6344 - accuracy: 0.6477 - val_loss: 0.6332 - val_accuracy: 0.6504\n",
      "Epoch 55/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6341 - accuracy: 0.6477 - val_loss: 0.6328 - val_accuracy: 0.6504\n",
      "Epoch 56/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6337 - accuracy: 0.6477 - val_loss: 0.6325 - val_accuracy: 0.6504\n",
      "Epoch 57/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.6334 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6504\n",
      "Epoch 58/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6331 - accuracy: 0.6477 - val_loss: 0.6318 - val_accuracy: 0.6504\n",
      "Epoch 59/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.6328 - accuracy: 0.6477 - val_loss: 0.6315 - val_accuracy: 0.6504\n",
      "Epoch 60/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6324 - accuracy: 0.6477 - val_loss: 0.6312 - val_accuracy: 0.6504\n",
      "Epoch 61/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6321 - accuracy: 0.6477 - val_loss: 0.6309 - val_accuracy: 0.6504\n",
      "Epoch 62/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6317 - accuracy: 0.6477 - val_loss: 0.6306 - val_accuracy: 0.6504\n",
      "Epoch 63/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.6314 - accuracy: 0.6477 - val_loss: 0.6302 - val_accuracy: 0.6504\n",
      "Epoch 64/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.6311 - accuracy: 0.6477 - val_loss: 0.6299 - val_accuracy: 0.6504\n",
      "Epoch 65/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.6307 - accuracy: 0.6477 - val_loss: 0.6296 - val_accuracy: 0.6504\n",
      "Epoch 66/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6304 - accuracy: 0.6477 - val_loss: 0.6293 - val_accuracy: 0.6504\n",
      "Epoch 67/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6300 - accuracy: 0.6477 - val_loss: 0.6289 - val_accuracy: 0.6504\n",
      "Epoch 68/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.6297 - accuracy: 0.6477 - val_loss: 0.6286 - val_accuracy: 0.6504\n",
      "Epoch 69/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6293 - accuracy: 0.6477 - val_loss: 0.6283 - val_accuracy: 0.6504\n",
      "Epoch 70/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6289 - accuracy: 0.6477 - val_loss: 0.6279 - val_accuracy: 0.6504\n",
      "Epoch 71/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6286 - accuracy: 0.6477 - val_loss: 0.6276 - val_accuracy: 0.6504\n",
      "Epoch 72/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6283 - accuracy: 0.6477 - val_loss: 0.6272 - val_accuracy: 0.6504\n",
      "Epoch 73/1000\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.6278 - accuracy: 0.6477 - val_loss: 0.6269 - val_accuracy: 0.6504\n",
      "Epoch 74/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.6276 - accuracy: 0.6477 - val_loss: 0.6266 - val_accuracy: 0.6585\n",
      "Epoch 75/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6272 - accuracy: 0.6477 - val_loss: 0.6262 - val_accuracy: 0.6585\n",
      "Epoch 76/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6268 - accuracy: 0.6477 - val_loss: 0.6259 - val_accuracy: 0.6585\n",
      "Epoch 77/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.6265 - accuracy: 0.6477 - val_loss: 0.6256 - val_accuracy: 0.6585\n",
      "Epoch 78/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6252 - val_accuracy: 0.6585\n",
      "Epoch 79/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6258 - accuracy: 0.6477 - val_loss: 0.6249 - val_accuracy: 0.6585\n",
      "Epoch 80/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6255 - accuracy: 0.6477 - val_loss: 0.6246 - val_accuracy: 0.6585\n",
      "Epoch 81/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.6252 - accuracy: 0.6477 - val_loss: 0.6243 - val_accuracy: 0.6585\n",
      "Epoch 82/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6248 - accuracy: 0.6477 - val_loss: 0.6240 - val_accuracy: 0.6585\n",
      "Epoch 83/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.6244 - accuracy: 0.6477 - val_loss: 0.6237 - val_accuracy: 0.6585\n",
      "Epoch 84/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.6241 - accuracy: 0.6477 - val_loss: 0.6234 - val_accuracy: 0.6585\n",
      "Epoch 85/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6239 - accuracy: 0.6477 - val_loss: 0.6231 - val_accuracy: 0.6585\n",
      "Epoch 86/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6235 - accuracy: 0.6477 - val_loss: 0.6228 - val_accuracy: 0.6585\n",
      "Epoch 87/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6232 - accuracy: 0.6477 - val_loss: 0.6225 - val_accuracy: 0.6585\n",
      "Epoch 88/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.6228 - accuracy: 0.6477 - val_loss: 0.6221 - val_accuracy: 0.6585\n",
      "Epoch 89/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6225 - accuracy: 0.6477 - val_loss: 0.6219 - val_accuracy: 0.6585\n",
      "Epoch 90/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6222 - accuracy: 0.6477 - val_loss: 0.6216 - val_accuracy: 0.6585\n",
      "Epoch 91/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6218 - accuracy: 0.6477 - val_loss: 0.6213 - val_accuracy: 0.6585\n",
      "Epoch 92/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6215 - accuracy: 0.6477 - val_loss: 0.6210 - val_accuracy: 0.6585\n",
      "Epoch 93/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.6211 - accuracy: 0.6477 - val_loss: 0.6207 - val_accuracy: 0.6585\n",
      "Epoch 94/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6207 - accuracy: 0.6477 - val_loss: 0.6204 - val_accuracy: 0.6585\n",
      "Epoch 95/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.6205 - accuracy: 0.6477 - val_loss: 0.6200 - val_accuracy: 0.6585\n",
      "Epoch 96/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.6201 - accuracy: 0.6477 - val_loss: 0.6198 - val_accuracy: 0.6585\n",
      "Epoch 97/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.6197 - accuracy: 0.6477 - val_loss: 0.6195 - val_accuracy: 0.6585\n",
      "Epoch 98/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.6194 - accuracy: 0.6477 - val_loss: 0.6192 - val_accuracy: 0.6585\n",
      "Epoch 99/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.6191 - accuracy: 0.6497 - val_loss: 0.6189 - val_accuracy: 0.6585\n",
      "Epoch 100/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6187 - accuracy: 0.6497 - val_loss: 0.6186 - val_accuracy: 0.6585\n",
      "Epoch 101/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.6185 - accuracy: 0.6497 - val_loss: 0.6183 - val_accuracy: 0.6585\n",
      "Epoch 102/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6181 - accuracy: 0.6497 - val_loss: 0.6180 - val_accuracy: 0.6585\n",
      "Epoch 103/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6178 - accuracy: 0.6497 - val_loss: 0.6177 - val_accuracy: 0.6585\n",
      "Epoch 104/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.6173 - accuracy: 0.6497 - val_loss: 0.6174 - val_accuracy: 0.6585\n",
      "Epoch 105/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6170 - accuracy: 0.6497 - val_loss: 0.6171 - val_accuracy: 0.6585\n",
      "Epoch 106/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6167 - accuracy: 0.6538 - val_loss: 0.6167 - val_accuracy: 0.6585\n",
      "Epoch 107/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6164 - accuracy: 0.6517 - val_loss: 0.6165 - val_accuracy: 0.6585\n",
      "Epoch 108/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6161 - accuracy: 0.6538 - val_loss: 0.6162 - val_accuracy: 0.6585\n",
      "Epoch 109/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6157 - accuracy: 0.6558 - val_loss: 0.6159 - val_accuracy: 0.6585\n",
      "Epoch 110/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.6155 - accuracy: 0.6558 - val_loss: 0.6155 - val_accuracy: 0.6585\n",
      "Epoch 111/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6151 - accuracy: 0.6558 - val_loss: 0.6152 - val_accuracy: 0.6585\n",
      "Epoch 112/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6147 - accuracy: 0.6558 - val_loss: 0.6149 - val_accuracy: 0.6504\n",
      "Epoch 113/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.6144 - accuracy: 0.6558 - val_loss: 0.6146 - val_accuracy: 0.6504\n",
      "Epoch 114/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6140 - accuracy: 0.6558 - val_loss: 0.6143 - val_accuracy: 0.6504\n",
      "Epoch 115/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6136 - accuracy: 0.6558 - val_loss: 0.6140 - val_accuracy: 0.6504\n",
      "Epoch 116/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.6133 - accuracy: 0.6578 - val_loss: 0.6137 - val_accuracy: 0.6504\n",
      "Epoch 117/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.6129 - accuracy: 0.6599 - val_loss: 0.6134 - val_accuracy: 0.6585\n",
      "Epoch 118/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.6125 - accuracy: 0.6640 - val_loss: 0.6131 - val_accuracy: 0.6585\n",
      "Epoch 119/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6122 - accuracy: 0.6640 - val_loss: 0.6129 - val_accuracy: 0.6585\n",
      "Epoch 120/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6120 - accuracy: 0.6640 - val_loss: 0.6126 - val_accuracy: 0.6585\n",
      "Epoch 121/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6115 - accuracy: 0.6660 - val_loss: 0.6123 - val_accuracy: 0.6585\n",
      "Epoch 122/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.6112 - accuracy: 0.6680 - val_loss: 0.6119 - val_accuracy: 0.6504\n",
      "Epoch 123/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6108 - accuracy: 0.6680 - val_loss: 0.6116 - val_accuracy: 0.6504\n",
      "Epoch 124/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6104 - accuracy: 0.6680 - val_loss: 0.6113 - val_accuracy: 0.6504\n",
      "Epoch 125/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6100 - accuracy: 0.6701 - val_loss: 0.6110 - val_accuracy: 0.6504\n",
      "Epoch 126/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.6097 - accuracy: 0.6721 - val_loss: 0.6107 - val_accuracy: 0.6504\n",
      "Epoch 127/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6093 - accuracy: 0.6721 - val_loss: 0.6104 - val_accuracy: 0.6504\n",
      "Epoch 128/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6090 - accuracy: 0.6721 - val_loss: 0.6100 - val_accuracy: 0.6504\n",
      "Epoch 129/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6085 - accuracy: 0.6721 - val_loss: 0.6097 - val_accuracy: 0.6504\n",
      "Epoch 130/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.6082 - accuracy: 0.6721 - val_loss: 0.6094 - val_accuracy: 0.6504\n",
      "Epoch 131/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6078 - accuracy: 0.6721 - val_loss: 0.6091 - val_accuracy: 0.6504\n",
      "Epoch 132/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6075 - accuracy: 0.6721 - val_loss: 0.6088 - val_accuracy: 0.6504\n",
      "Epoch 133/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.6072 - accuracy: 0.6721 - val_loss: 0.6085 - val_accuracy: 0.6504\n",
      "Epoch 134/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.6068 - accuracy: 0.6701 - val_loss: 0.6082 - val_accuracy: 0.6504\n",
      "Epoch 135/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6064 - accuracy: 0.6701 - val_loss: 0.6079 - val_accuracy: 0.6504\n",
      "Epoch 136/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.6061 - accuracy: 0.6701 - val_loss: 0.6076 - val_accuracy: 0.6504\n",
      "Epoch 137/1000\n",
      "491/491 [==============================] - 0s 36us/step - loss: 0.6056 - accuracy: 0.6741 - val_loss: 0.6073 - val_accuracy: 0.6504\n",
      "Epoch 138/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6052 - accuracy: 0.6741 - val_loss: 0.6069 - val_accuracy: 0.6585\n",
      "Epoch 139/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.6048 - accuracy: 0.6741 - val_loss: 0.6066 - val_accuracy: 0.6585\n",
      "Epoch 140/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.6044 - accuracy: 0.6782 - val_loss: 0.6063 - val_accuracy: 0.6667\n",
      "Epoch 141/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6041 - accuracy: 0.6762 - val_loss: 0.6060 - val_accuracy: 0.6667\n",
      "Epoch 142/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6037 - accuracy: 0.6741 - val_loss: 0.6056 - val_accuracy: 0.6585\n",
      "Epoch 143/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.6033 - accuracy: 0.6762 - val_loss: 0.6053 - val_accuracy: 0.6585\n",
      "Epoch 144/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6030 - accuracy: 0.6762 - val_loss: 0.6050 - val_accuracy: 0.6504\n",
      "Epoch 145/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6025 - accuracy: 0.6762 - val_loss: 0.6046 - val_accuracy: 0.6504\n",
      "Epoch 146/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6022 - accuracy: 0.6762 - val_loss: 0.6043 - val_accuracy: 0.6585\n",
      "Epoch 147/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.6017 - accuracy: 0.6782 - val_loss: 0.6040 - val_accuracy: 0.6585\n",
      "Epoch 148/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.6014 - accuracy: 0.6782 - val_loss: 0.6037 - val_accuracy: 0.6667\n",
      "Epoch 149/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6009 - accuracy: 0.6782 - val_loss: 0.6034 - val_accuracy: 0.6748\n",
      "Epoch 150/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.6006 - accuracy: 0.6782 - val_loss: 0.6031 - val_accuracy: 0.6748\n",
      "Epoch 151/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.6001 - accuracy: 0.6782 - val_loss: 0.6028 - val_accuracy: 0.6748\n",
      "Epoch 152/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.6000 - accuracy: 0.6823 - val_loss: 0.6024 - val_accuracy: 0.6748\n",
      "Epoch 153/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5994 - accuracy: 0.6802 - val_loss: 0.6021 - val_accuracy: 0.6748\n",
      "Epoch 154/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5990 - accuracy: 0.6843 - val_loss: 0.6017 - val_accuracy: 0.6748\n",
      "Epoch 155/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5987 - accuracy: 0.6823 - val_loss: 0.6014 - val_accuracy: 0.6748\n",
      "Epoch 156/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5982 - accuracy: 0.6843 - val_loss: 0.6011 - val_accuracy: 0.6667\n",
      "Epoch 157/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5977 - accuracy: 0.6864 - val_loss: 0.6008 - val_accuracy: 0.6667\n",
      "Epoch 158/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5975 - accuracy: 0.6864 - val_loss: 0.6005 - val_accuracy: 0.6748\n",
      "Epoch 159/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5970 - accuracy: 0.6864 - val_loss: 0.6003 - val_accuracy: 0.6748\n",
      "Epoch 160/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5967 - accuracy: 0.6904 - val_loss: 0.5999 - val_accuracy: 0.6748\n",
      "Epoch 161/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5962 - accuracy: 0.6864 - val_loss: 0.5996 - val_accuracy: 0.6829\n",
      "Epoch 162/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5957 - accuracy: 0.6884 - val_loss: 0.5993 - val_accuracy: 0.6829\n",
      "Epoch 163/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5953 - accuracy: 0.6945 - val_loss: 0.5989 - val_accuracy: 0.6829\n",
      "Epoch 164/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5949 - accuracy: 0.6945 - val_loss: 0.5985 - val_accuracy: 0.6829\n",
      "Epoch 165/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5945 - accuracy: 0.6945 - val_loss: 0.5982 - val_accuracy: 0.6829\n",
      "Epoch 166/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5941 - accuracy: 0.6945 - val_loss: 0.5979 - val_accuracy: 0.6829\n",
      "Epoch 167/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5937 - accuracy: 0.6925 - val_loss: 0.5975 - val_accuracy: 0.6829\n",
      "Epoch 168/1000\n",
      "491/491 [==============================] - 0s 97us/step - loss: 0.5933 - accuracy: 0.6925 - val_loss: 0.5972 - val_accuracy: 0.6829\n",
      "Epoch 169/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5929 - accuracy: 0.6925 - val_loss: 0.5968 - val_accuracy: 0.6829\n",
      "Epoch 170/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5925 - accuracy: 0.6925 - val_loss: 0.5965 - val_accuracy: 0.6829\n",
      "Epoch 171/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5921 - accuracy: 0.6925 - val_loss: 0.5962 - val_accuracy: 0.6829\n",
      "Epoch 172/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5915 - accuracy: 0.6986 - val_loss: 0.5958 - val_accuracy: 0.6911\n",
      "Epoch 173/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5911 - accuracy: 0.6965 - val_loss: 0.5956 - val_accuracy: 0.6911\n",
      "Epoch 174/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5907 - accuracy: 0.7026 - val_loss: 0.5952 - val_accuracy: 0.6911\n",
      "Epoch 175/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5903 - accuracy: 0.7026 - val_loss: 0.5948 - val_accuracy: 0.6911\n",
      "Epoch 176/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5900 - accuracy: 0.7006 - val_loss: 0.5945 - val_accuracy: 0.6911\n",
      "Epoch 177/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5896 - accuracy: 0.7006 - val_loss: 0.5942 - val_accuracy: 0.6911\n",
      "Epoch 178/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5892 - accuracy: 0.7006 - val_loss: 0.5939 - val_accuracy: 0.6992\n",
      "Epoch 179/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5888 - accuracy: 0.6986 - val_loss: 0.5936 - val_accuracy: 0.6992\n",
      "Epoch 180/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5882 - accuracy: 0.6986 - val_loss: 0.5932 - val_accuracy: 0.6992\n",
      "Epoch 181/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5877 - accuracy: 0.6986 - val_loss: 0.5928 - val_accuracy: 0.6992\n",
      "Epoch 182/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5873 - accuracy: 0.6986 - val_loss: 0.5925 - val_accuracy: 0.6911\n",
      "Epoch 183/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5868 - accuracy: 0.7006 - val_loss: 0.5922 - val_accuracy: 0.6911\n",
      "Epoch 184/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5866 - accuracy: 0.7006 - val_loss: 0.5919 - val_accuracy: 0.6911\n",
      "Epoch 185/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5862 - accuracy: 0.7006 - val_loss: 0.5915 - val_accuracy: 0.6829\n",
      "Epoch 186/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5855 - accuracy: 0.6986 - val_loss: 0.5912 - val_accuracy: 0.6911\n",
      "Epoch 187/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5851 - accuracy: 0.7026 - val_loss: 0.5908 - val_accuracy: 0.6829\n",
      "Epoch 188/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5849 - accuracy: 0.7026 - val_loss: 0.5905 - val_accuracy: 0.6829\n",
      "Epoch 189/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5843 - accuracy: 0.7047 - val_loss: 0.5901 - val_accuracy: 0.6829\n",
      "Epoch 190/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5840 - accuracy: 0.7067 - val_loss: 0.5897 - val_accuracy: 0.6829\n",
      "Epoch 191/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5836 - accuracy: 0.7067 - val_loss: 0.5894 - val_accuracy: 0.6829\n",
      "Epoch 192/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5831 - accuracy: 0.7088 - val_loss: 0.5891 - val_accuracy: 0.6829\n",
      "Epoch 193/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.5827 - accuracy: 0.7067 - val_loss: 0.5887 - val_accuracy: 0.6829\n",
      "Epoch 194/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5822 - accuracy: 0.7067 - val_loss: 0.5884 - val_accuracy: 0.6829\n",
      "Epoch 195/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5817 - accuracy: 0.7067 - val_loss: 0.5880 - val_accuracy: 0.6829\n",
      "Epoch 196/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5814 - accuracy: 0.7047 - val_loss: 0.5876 - val_accuracy: 0.6829\n",
      "Epoch 197/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5809 - accuracy: 0.7047 - val_loss: 0.5873 - val_accuracy: 0.6829\n",
      "Epoch 198/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5804 - accuracy: 0.7067 - val_loss: 0.5868 - val_accuracy: 0.6829\n",
      "Epoch 199/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5800 - accuracy: 0.7026 - val_loss: 0.5865 - val_accuracy: 0.6829\n",
      "Epoch 200/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5795 - accuracy: 0.7047 - val_loss: 0.5862 - val_accuracy: 0.6829\n",
      "Epoch 201/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5791 - accuracy: 0.7026 - val_loss: 0.5858 - val_accuracy: 0.6829\n",
      "Epoch 202/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5787 - accuracy: 0.7047 - val_loss: 0.5855 - val_accuracy: 0.6829\n",
      "Epoch 203/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5783 - accuracy: 0.7026 - val_loss: 0.5851 - val_accuracy: 0.6829\n",
      "Epoch 204/1000\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.5777 - accuracy: 0.7047 - val_loss: 0.5847 - val_accuracy: 0.6829\n",
      "Epoch 205/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5772 - accuracy: 0.7047 - val_loss: 0.5843 - val_accuracy: 0.6829\n",
      "Epoch 206/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5769 - accuracy: 0.7047 - val_loss: 0.5840 - val_accuracy: 0.6829\n",
      "Epoch 207/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5765 - accuracy: 0.7047 - val_loss: 0.5836 - val_accuracy: 0.6829\n",
      "Epoch 208/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5759 - accuracy: 0.7047 - val_loss: 0.5833 - val_accuracy: 0.6911\n",
      "Epoch 209/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5755 - accuracy: 0.7067 - val_loss: 0.5830 - val_accuracy: 0.6911\n",
      "Epoch 210/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5752 - accuracy: 0.7047 - val_loss: 0.5827 - val_accuracy: 0.6911\n",
      "Epoch 211/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5747 - accuracy: 0.7067 - val_loss: 0.5824 - val_accuracy: 0.6829\n",
      "Epoch 212/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5743 - accuracy: 0.7067 - val_loss: 0.5820 - val_accuracy: 0.6911\n",
      "Epoch 213/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5737 - accuracy: 0.7047 - val_loss: 0.5816 - val_accuracy: 0.6911\n",
      "Epoch 214/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5733 - accuracy: 0.7047 - val_loss: 0.5812 - val_accuracy: 0.6911\n",
      "Epoch 215/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5727 - accuracy: 0.7067 - val_loss: 0.5809 - val_accuracy: 0.6829\n",
      "Epoch 216/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5723 - accuracy: 0.7067 - val_loss: 0.5806 - val_accuracy: 0.6829\n",
      "Epoch 217/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5719 - accuracy: 0.7047 - val_loss: 0.5802 - val_accuracy: 0.6829\n",
      "Epoch 218/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5714 - accuracy: 0.7026 - val_loss: 0.5799 - val_accuracy: 0.6829\n",
      "Epoch 219/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5711 - accuracy: 0.7047 - val_loss: 0.5795 - val_accuracy: 0.6829\n",
      "Epoch 220/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.5706 - accuracy: 0.7067 - val_loss: 0.5792 - val_accuracy: 0.6829\n",
      "Epoch 221/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5702 - accuracy: 0.7026 - val_loss: 0.5789 - val_accuracy: 0.6829\n",
      "Epoch 222/1000\n",
      "491/491 [==============================] - 0s 36us/step - loss: 0.5700 - accuracy: 0.7067 - val_loss: 0.5786 - val_accuracy: 0.6829\n",
      "Epoch 223/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5694 - accuracy: 0.7047 - val_loss: 0.5782 - val_accuracy: 0.6829\n",
      "Epoch 224/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5688 - accuracy: 0.7047 - val_loss: 0.5778 - val_accuracy: 0.6829\n",
      "Epoch 225/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5683 - accuracy: 0.7047 - val_loss: 0.5774 - val_accuracy: 0.6829\n",
      "Epoch 226/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5680 - accuracy: 0.7047 - val_loss: 0.5771 - val_accuracy: 0.6829\n",
      "Epoch 227/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5675 - accuracy: 0.7047 - val_loss: 0.5768 - val_accuracy: 0.6748\n",
      "Epoch 228/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5670 - accuracy: 0.7047 - val_loss: 0.5765 - val_accuracy: 0.6667\n",
      "Epoch 229/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5666 - accuracy: 0.7006 - val_loss: 0.5761 - val_accuracy: 0.6748\n",
      "Epoch 230/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5661 - accuracy: 0.7006 - val_loss: 0.5758 - val_accuracy: 0.6667\n",
      "Epoch 231/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5656 - accuracy: 0.7006 - val_loss: 0.5755 - val_accuracy: 0.6667\n",
      "Epoch 232/1000\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.5652 - accuracy: 0.6986 - val_loss: 0.5752 - val_accuracy: 0.6829\n",
      "Epoch 233/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5648 - accuracy: 0.7006 - val_loss: 0.5749 - val_accuracy: 0.6829\n",
      "Epoch 234/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5647 - accuracy: 0.7006 - val_loss: 0.5746 - val_accuracy: 0.6829\n",
      "Epoch 235/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5639 - accuracy: 0.7006 - val_loss: 0.5743 - val_accuracy: 0.6748\n",
      "Epoch 236/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5635 - accuracy: 0.6965 - val_loss: 0.5739 - val_accuracy: 0.6748\n",
      "Epoch 237/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5632 - accuracy: 0.6965 - val_loss: 0.5736 - val_accuracy: 0.6748\n",
      "Epoch 238/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5625 - accuracy: 0.7006 - val_loss: 0.5733 - val_accuracy: 0.6748\n",
      "Epoch 239/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5621 - accuracy: 0.7006 - val_loss: 0.5729 - val_accuracy: 0.6748\n",
      "Epoch 240/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5617 - accuracy: 0.7047 - val_loss: 0.5725 - val_accuracy: 0.6748\n",
      "Epoch 241/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5613 - accuracy: 0.7026 - val_loss: 0.5723 - val_accuracy: 0.6748\n",
      "Epoch 242/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5609 - accuracy: 0.7047 - val_loss: 0.5720 - val_accuracy: 0.6748\n",
      "Epoch 243/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5605 - accuracy: 0.7047 - val_loss: 0.5718 - val_accuracy: 0.6748\n",
      "Epoch 244/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5600 - accuracy: 0.7047 - val_loss: 0.5714 - val_accuracy: 0.6748\n",
      "Epoch 245/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5594 - accuracy: 0.7047 - val_loss: 0.5712 - val_accuracy: 0.6911\n",
      "Epoch 246/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5591 - accuracy: 0.7006 - val_loss: 0.5708 - val_accuracy: 0.6829\n",
      "Epoch 247/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5586 - accuracy: 0.7026 - val_loss: 0.5706 - val_accuracy: 0.6911\n",
      "Epoch 248/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5582 - accuracy: 0.6986 - val_loss: 0.5702 - val_accuracy: 0.6911\n",
      "Epoch 249/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5578 - accuracy: 0.7006 - val_loss: 0.5698 - val_accuracy: 0.6911\n",
      "Epoch 250/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5573 - accuracy: 0.7047 - val_loss: 0.5695 - val_accuracy: 0.6911\n",
      "Epoch 251/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5570 - accuracy: 0.6986 - val_loss: 0.5693 - val_accuracy: 0.6911\n",
      "Epoch 252/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5564 - accuracy: 0.7006 - val_loss: 0.5689 - val_accuracy: 0.6911\n",
      "Epoch 253/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5562 - accuracy: 0.7006 - val_loss: 0.5686 - val_accuracy: 0.6911\n",
      "Epoch 254/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5558 - accuracy: 0.6986 - val_loss: 0.5682 - val_accuracy: 0.6911\n",
      "Epoch 255/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5554 - accuracy: 0.7047 - val_loss: 0.5679 - val_accuracy: 0.6911\n",
      "Epoch 256/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5549 - accuracy: 0.7026 - val_loss: 0.5677 - val_accuracy: 0.6911\n",
      "Epoch 257/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5542 - accuracy: 0.7026 - val_loss: 0.5672 - val_accuracy: 0.6829\n",
      "Epoch 258/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5539 - accuracy: 0.7047 - val_loss: 0.5669 - val_accuracy: 0.6911\n",
      "Epoch 259/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5533 - accuracy: 0.6986 - val_loss: 0.5666 - val_accuracy: 0.6911\n",
      "Epoch 260/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.5530 - accuracy: 0.7026 - val_loss: 0.5662 - val_accuracy: 0.6911\n",
      "Epoch 261/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5525 - accuracy: 0.7026 - val_loss: 0.5660 - val_accuracy: 0.6911\n",
      "Epoch 262/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5524 - accuracy: 0.6986 - val_loss: 0.5657 - val_accuracy: 0.6911\n",
      "Epoch 263/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5518 - accuracy: 0.7067 - val_loss: 0.5654 - val_accuracy: 0.6911\n",
      "Epoch 264/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5511 - accuracy: 0.7026 - val_loss: 0.5650 - val_accuracy: 0.6911\n",
      "Epoch 265/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5509 - accuracy: 0.7047 - val_loss: 0.5647 - val_accuracy: 0.6911\n",
      "Epoch 266/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5506 - accuracy: 0.7047 - val_loss: 0.5643 - val_accuracy: 0.6911\n",
      "Epoch 267/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5502 - accuracy: 0.7047 - val_loss: 0.5643 - val_accuracy: 0.6911\n",
      "Epoch 268/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5495 - accuracy: 0.7006 - val_loss: 0.5640 - val_accuracy: 0.6911\n",
      "Epoch 269/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5491 - accuracy: 0.7006 - val_loss: 0.5636 - val_accuracy: 0.6911\n",
      "Epoch 270/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5486 - accuracy: 0.7026 - val_loss: 0.5633 - val_accuracy: 0.6911\n",
      "Epoch 271/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5483 - accuracy: 0.7006 - val_loss: 0.5631 - val_accuracy: 0.6829\n",
      "Epoch 272/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5480 - accuracy: 0.7026 - val_loss: 0.5626 - val_accuracy: 0.6911\n",
      "Epoch 273/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5474 - accuracy: 0.7006 - val_loss: 0.5624 - val_accuracy: 0.6911\n",
      "Epoch 274/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5469 - accuracy: 0.7006 - val_loss: 0.5621 - val_accuracy: 0.6911\n",
      "Epoch 275/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5465 - accuracy: 0.7006 - val_loss: 0.5620 - val_accuracy: 0.6829\n",
      "Epoch 276/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5460 - accuracy: 0.7047 - val_loss: 0.5617 - val_accuracy: 0.6829\n",
      "Epoch 277/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5456 - accuracy: 0.7067 - val_loss: 0.5613 - val_accuracy: 0.6829\n",
      "Epoch 278/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5454 - accuracy: 0.7047 - val_loss: 0.5610 - val_accuracy: 0.6829\n",
      "Epoch 279/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5449 - accuracy: 0.7047 - val_loss: 0.5607 - val_accuracy: 0.6829\n",
      "Epoch 280/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5443 - accuracy: 0.7067 - val_loss: 0.5604 - val_accuracy: 0.6829\n",
      "Epoch 281/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5440 - accuracy: 0.7067 - val_loss: 0.5601 - val_accuracy: 0.6829\n",
      "Epoch 282/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5438 - accuracy: 0.7047 - val_loss: 0.5598 - val_accuracy: 0.6829\n",
      "Epoch 283/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5433 - accuracy: 0.7047 - val_loss: 0.5595 - val_accuracy: 0.6829\n",
      "Epoch 284/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5426 - accuracy: 0.7067 - val_loss: 0.5593 - val_accuracy: 0.6829\n",
      "Epoch 285/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5425 - accuracy: 0.7088 - val_loss: 0.5590 - val_accuracy: 0.6829\n",
      "Epoch 286/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5418 - accuracy: 0.7047 - val_loss: 0.5587 - val_accuracy: 0.6829\n",
      "Epoch 287/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5416 - accuracy: 0.7067 - val_loss: 0.5585 - val_accuracy: 0.6829\n",
      "Epoch 288/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5411 - accuracy: 0.7088 - val_loss: 0.5581 - val_accuracy: 0.6829\n",
      "Epoch 289/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5407 - accuracy: 0.7088 - val_loss: 0.5579 - val_accuracy: 0.6829\n",
      "Epoch 290/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5403 - accuracy: 0.7067 - val_loss: 0.5576 - val_accuracy: 0.6829\n",
      "Epoch 291/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5400 - accuracy: 0.7067 - val_loss: 0.5574 - val_accuracy: 0.6911\n",
      "Epoch 292/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5395 - accuracy: 0.7047 - val_loss: 0.5571 - val_accuracy: 0.6911\n",
      "Epoch 293/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5393 - accuracy: 0.7067 - val_loss: 0.5566 - val_accuracy: 0.6829\n",
      "Epoch 294/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5388 - accuracy: 0.7108 - val_loss: 0.5565 - val_accuracy: 0.6992\n",
      "Epoch 295/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5383 - accuracy: 0.7088 - val_loss: 0.5564 - val_accuracy: 0.6992\n",
      "Epoch 296/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5384 - accuracy: 0.7088 - val_loss: 0.5560 - val_accuracy: 0.6992\n",
      "Epoch 297/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.5376 - accuracy: 0.7108 - val_loss: 0.5557 - val_accuracy: 0.6992\n",
      "Epoch 298/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5372 - accuracy: 0.7088 - val_loss: 0.5554 - val_accuracy: 0.6992\n",
      "Epoch 299/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5370 - accuracy: 0.7108 - val_loss: 0.5552 - val_accuracy: 0.6992\n",
      "Epoch 300/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5363 - accuracy: 0.7067 - val_loss: 0.5548 - val_accuracy: 0.6992\n",
      "Epoch 301/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5364 - accuracy: 0.7047 - val_loss: 0.5545 - val_accuracy: 0.6992\n",
      "Epoch 302/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5360 - accuracy: 0.7088 - val_loss: 0.5543 - val_accuracy: 0.6992\n",
      "Epoch 303/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5353 - accuracy: 0.7067 - val_loss: 0.5539 - val_accuracy: 0.6992\n",
      "Epoch 304/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5350 - accuracy: 0.7088 - val_loss: 0.5537 - val_accuracy: 0.6992\n",
      "Epoch 305/1000\n",
      "491/491 [==============================] - 0s 120us/step - loss: 0.5345 - accuracy: 0.7067 - val_loss: 0.5534 - val_accuracy: 0.6992\n",
      "Epoch 306/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5342 - accuracy: 0.7088 - val_loss: 0.5531 - val_accuracy: 0.6992\n",
      "Epoch 307/1000\n",
      "491/491 [==============================] - 0s 108us/step - loss: 0.5337 - accuracy: 0.7108 - val_loss: 0.5529 - val_accuracy: 0.6992\n",
      "Epoch 308/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5336 - accuracy: 0.7067 - val_loss: 0.5526 - val_accuracy: 0.6992\n",
      "Epoch 309/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5330 - accuracy: 0.7128 - val_loss: 0.5523 - val_accuracy: 0.6992\n",
      "Epoch 310/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5328 - accuracy: 0.7108 - val_loss: 0.5521 - val_accuracy: 0.6992\n",
      "Epoch 311/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5324 - accuracy: 0.7108 - val_loss: 0.5518 - val_accuracy: 0.6992\n",
      "Epoch 312/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5321 - accuracy: 0.7047 - val_loss: 0.5515 - val_accuracy: 0.7073\n",
      "Epoch 313/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5317 - accuracy: 0.7067 - val_loss: 0.5512 - val_accuracy: 0.6992\n",
      "Epoch 314/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5314 - accuracy: 0.7047 - val_loss: 0.5510 - val_accuracy: 0.7073\n",
      "Epoch 315/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5308 - accuracy: 0.7128 - val_loss: 0.5507 - val_accuracy: 0.7073\n",
      "Epoch 316/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5306 - accuracy: 0.7128 - val_loss: 0.5505 - val_accuracy: 0.6992\n",
      "Epoch 317/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5303 - accuracy: 0.7088 - val_loss: 0.5503 - val_accuracy: 0.6992\n",
      "Epoch 318/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5297 - accuracy: 0.7128 - val_loss: 0.5501 - val_accuracy: 0.6829\n",
      "Epoch 319/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.5293 - accuracy: 0.7088 - val_loss: 0.5499 - val_accuracy: 0.6829\n",
      "Epoch 320/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5289 - accuracy: 0.7088 - val_loss: 0.5496 - val_accuracy: 0.6911\n",
      "Epoch 321/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5285 - accuracy: 0.7088 - val_loss: 0.5496 - val_accuracy: 0.6911\n",
      "Epoch 322/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5282 - accuracy: 0.7108 - val_loss: 0.5493 - val_accuracy: 0.6911\n",
      "Epoch 323/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5277 - accuracy: 0.7047 - val_loss: 0.5488 - val_accuracy: 0.6911\n",
      "Epoch 324/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5274 - accuracy: 0.7067 - val_loss: 0.5484 - val_accuracy: 0.6829\n",
      "Epoch 325/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5266 - accuracy: 0.7067 - val_loss: 0.5482 - val_accuracy: 0.6748\n",
      "Epoch 326/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5265 - accuracy: 0.7088 - val_loss: 0.5480 - val_accuracy: 0.6911\n",
      "Epoch 327/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.5263 - accuracy: 0.7088 - val_loss: 0.5476 - val_accuracy: 0.6829\n",
      "Epoch 328/1000\n",
      "491/491 [==============================] - 0s 42us/step - loss: 0.5257 - accuracy: 0.7026 - val_loss: 0.5475 - val_accuracy: 0.6829\n",
      "Epoch 329/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.5256 - accuracy: 0.7128 - val_loss: 0.5472 - val_accuracy: 0.6911\n",
      "Epoch 330/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5252 - accuracy: 0.7067 - val_loss: 0.5470 - val_accuracy: 0.6829\n",
      "Epoch 331/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5248 - accuracy: 0.7088 - val_loss: 0.5467 - val_accuracy: 0.6829\n",
      "Epoch 332/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5244 - accuracy: 0.7088 - val_loss: 0.5465 - val_accuracy: 0.6829\n",
      "Epoch 333/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5237 - accuracy: 0.7128 - val_loss: 0.5463 - val_accuracy: 0.6829\n",
      "Epoch 334/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5235 - accuracy: 0.7108 - val_loss: 0.5462 - val_accuracy: 0.6911\n",
      "Epoch 335/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5229 - accuracy: 0.7128 - val_loss: 0.5458 - val_accuracy: 0.6911\n",
      "Epoch 336/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5227 - accuracy: 0.7169 - val_loss: 0.5454 - val_accuracy: 0.6829\n",
      "Epoch 337/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5220 - accuracy: 0.7088 - val_loss: 0.5453 - val_accuracy: 0.6911\n",
      "Epoch 338/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5220 - accuracy: 0.7189 - val_loss: 0.5450 - val_accuracy: 0.6829\n",
      "Epoch 339/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5215 - accuracy: 0.7149 - val_loss: 0.5447 - val_accuracy: 0.6829\n",
      "Epoch 340/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5211 - accuracy: 0.7149 - val_loss: 0.5444 - val_accuracy: 0.6829\n",
      "Epoch 341/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.5206 - accuracy: 0.7149 - val_loss: 0.5442 - val_accuracy: 0.6829\n",
      "Epoch 342/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.5205 - accuracy: 0.7210 - val_loss: 0.5440 - val_accuracy: 0.6829\n",
      "Epoch 343/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.5198 - accuracy: 0.7230 - val_loss: 0.5438 - val_accuracy: 0.6911\n",
      "Epoch 344/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.5196 - accuracy: 0.7169 - val_loss: 0.5436 - val_accuracy: 0.6911\n",
      "Epoch 345/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5196 - accuracy: 0.7189 - val_loss: 0.5433 - val_accuracy: 0.6911\n",
      "Epoch 346/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5188 - accuracy: 0.7189 - val_loss: 0.5432 - val_accuracy: 0.6911\n",
      "Epoch 347/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5184 - accuracy: 0.7189 - val_loss: 0.5428 - val_accuracy: 0.6829\n",
      "Epoch 348/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.5181 - accuracy: 0.7189 - val_loss: 0.5426 - val_accuracy: 0.6829\n",
      "Epoch 349/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5175 - accuracy: 0.7271 - val_loss: 0.5424 - val_accuracy: 0.6911\n",
      "Epoch 350/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5171 - accuracy: 0.7210 - val_loss: 0.5421 - val_accuracy: 0.6911\n",
      "Epoch 351/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.5170 - accuracy: 0.7149 - val_loss: 0.5419 - val_accuracy: 0.6829\n",
      "Epoch 352/1000\n",
      "491/491 [==============================] - 0s 97us/step - loss: 0.5166 - accuracy: 0.7210 - val_loss: 0.5417 - val_accuracy: 0.6911\n",
      "Epoch 353/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5161 - accuracy: 0.7251 - val_loss: 0.5414 - val_accuracy: 0.6911\n",
      "Epoch 354/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5156 - accuracy: 0.7251 - val_loss: 0.5411 - val_accuracy: 0.6911\n",
      "Epoch 355/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.80 - 0s 73us/step - loss: 0.5154 - accuracy: 0.7312 - val_loss: 0.5410 - val_accuracy: 0.6911\n",
      "Epoch 356/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5150 - accuracy: 0.7230 - val_loss: 0.5407 - val_accuracy: 0.6748\n",
      "Epoch 357/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5148 - accuracy: 0.7251 - val_loss: 0.5404 - val_accuracy: 0.6911\n",
      "Epoch 358/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5140 - accuracy: 0.7271 - val_loss: 0.5402 - val_accuracy: 0.6829\n",
      "Epoch 359/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.5139 - accuracy: 0.7291 - val_loss: 0.5399 - val_accuracy: 0.6829\n",
      "Epoch 360/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5136 - accuracy: 0.7271 - val_loss: 0.5396 - val_accuracy: 0.6829\n",
      "Epoch 361/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5132 - accuracy: 0.7291 - val_loss: 0.5394 - val_accuracy: 0.6829\n",
      "Epoch 362/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5126 - accuracy: 0.7312 - val_loss: 0.5392 - val_accuracy: 0.6829\n",
      "Epoch 363/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.5123 - accuracy: 0.7332 - val_loss: 0.5389 - val_accuracy: 0.6829\n",
      "Epoch 364/1000\n",
      "491/491 [==============================] - 0s 132us/step - loss: 0.5118 - accuracy: 0.7271 - val_loss: 0.5386 - val_accuracy: 0.6911\n",
      "Epoch 365/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.5115 - accuracy: 0.7393 - val_loss: 0.5385 - val_accuracy: 0.6829\n",
      "Epoch 366/1000\n",
      "491/491 [==============================] - 0s 102us/step - loss: 0.5108 - accuracy: 0.7332 - val_loss: 0.5382 - val_accuracy: 0.6911\n",
      "Epoch 367/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.5107 - accuracy: 0.7312 - val_loss: 0.5380 - val_accuracy: 0.6911\n",
      "Epoch 368/1000\n",
      "491/491 [==============================] - 0s 91us/step - loss: 0.5102 - accuracy: 0.7373 - val_loss: 0.5378 - val_accuracy: 0.6911\n",
      "Epoch 369/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5100 - accuracy: 0.7373 - val_loss: 0.5376 - val_accuracy: 0.6911\n",
      "Epoch 370/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.5096 - accuracy: 0.7352 - val_loss: 0.5374 - val_accuracy: 0.6911\n",
      "Epoch 371/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5095 - accuracy: 0.7312 - val_loss: 0.5371 - val_accuracy: 0.6911\n",
      "Epoch 372/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5087 - accuracy: 0.7312 - val_loss: 0.5369 - val_accuracy: 0.6911\n",
      "Epoch 373/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5085 - accuracy: 0.7352 - val_loss: 0.5368 - val_accuracy: 0.6911\n",
      "Epoch 374/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5081 - accuracy: 0.7332 - val_loss: 0.5366 - val_accuracy: 0.6911\n",
      "Epoch 375/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5077 - accuracy: 0.7373 - val_loss: 0.5364 - val_accuracy: 0.6911\n",
      "Epoch 376/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.5076 - accuracy: 0.7312 - val_loss: 0.5363 - val_accuracy: 0.6911\n",
      "Epoch 377/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5073 - accuracy: 0.7312 - val_loss: 0.5361 - val_accuracy: 0.6911\n",
      "Epoch 378/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5070 - accuracy: 0.7312 - val_loss: 0.5358 - val_accuracy: 0.6911\n",
      "Epoch 379/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5065 - accuracy: 0.7352 - val_loss: 0.5355 - val_accuracy: 0.6911\n",
      "Epoch 380/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.5060 - accuracy: 0.7332 - val_loss: 0.5353 - val_accuracy: 0.6829\n",
      "Epoch 381/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5063 - accuracy: 0.7352 - val_loss: 0.5351 - val_accuracy: 0.6829\n",
      "Epoch 382/1000\n",
      "491/491 [==============================] - 0s 89us/step - loss: 0.5059 - accuracy: 0.7373 - val_loss: 0.5349 - val_accuracy: 0.6911\n",
      "Epoch 383/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5052 - accuracy: 0.7352 - val_loss: 0.5347 - val_accuracy: 0.6911\n",
      "Epoch 384/1000\n",
      "491/491 [==============================] - 0s 118us/step - loss: 0.5048 - accuracy: 0.7332 - val_loss: 0.5345 - val_accuracy: 0.6911\n",
      "Epoch 385/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.5045 - accuracy: 0.7352 - val_loss: 0.5344 - val_accuracy: 0.6992\n",
      "Epoch 386/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.5043 - accuracy: 0.7332 - val_loss: 0.5342 - val_accuracy: 0.6992\n",
      "Epoch 387/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.5039 - accuracy: 0.7332 - val_loss: 0.5339 - val_accuracy: 0.6992\n",
      "Epoch 388/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.5037 - accuracy: 0.7332 - val_loss: 0.5338 - val_accuracy: 0.6992\n",
      "Epoch 389/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.5034 - accuracy: 0.7332 - val_loss: 0.5335 - val_accuracy: 0.6992\n",
      "Epoch 390/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.5032 - accuracy: 0.7332 - val_loss: 0.5333 - val_accuracy: 0.6911\n",
      "Epoch 391/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.5028 - accuracy: 0.7352 - val_loss: 0.5331 - val_accuracy: 0.6911\n",
      "Epoch 392/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5024 - accuracy: 0.7332 - val_loss: 0.5329 - val_accuracy: 0.6911\n",
      "Epoch 393/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5018 - accuracy: 0.7332 - val_loss: 0.5327 - val_accuracy: 0.6992\n",
      "Epoch 394/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.5020 - accuracy: 0.7352 - val_loss: 0.5325 - val_accuracy: 0.6911\n",
      "Epoch 395/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.5013 - accuracy: 0.7373 - val_loss: 0.5324 - val_accuracy: 0.6992\n",
      "Epoch 396/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.5011 - accuracy: 0.7332 - val_loss: 0.5322 - val_accuracy: 0.6992\n",
      "Epoch 397/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.5008 - accuracy: 0.7332 - val_loss: 0.5320 - val_accuracy: 0.6911\n",
      "Epoch 398/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.5005 - accuracy: 0.7332 - val_loss: 0.5318 - val_accuracy: 0.6992\n",
      "Epoch 399/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.5007 - accuracy: 0.7352 - val_loss: 0.5317 - val_accuracy: 0.6911\n",
      "Epoch 400/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4998 - accuracy: 0.7373 - val_loss: 0.5315 - val_accuracy: 0.6911\n",
      "Epoch 401/1000\n",
      "491/491 [==============================] - 0s 122us/step - loss: 0.4995 - accuracy: 0.7373 - val_loss: 0.5313 - val_accuracy: 0.6911\n",
      "Epoch 402/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4994 - accuracy: 0.7393 - val_loss: 0.5311 - val_accuracy: 0.6992\n",
      "Epoch 403/1000\n",
      "491/491 [==============================] - 0s 91us/step - loss: 0.4992 - accuracy: 0.7352 - val_loss: 0.5309 - val_accuracy: 0.6911\n",
      "Epoch 404/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4986 - accuracy: 0.7352 - val_loss: 0.5308 - val_accuracy: 0.6992\n",
      "Epoch 405/1000\n",
      "491/491 [==============================] - 0s 89us/step - loss: 0.4985 - accuracy: 0.7373 - val_loss: 0.5306 - val_accuracy: 0.6992\n",
      "Epoch 406/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4983 - accuracy: 0.7393 - val_loss: 0.5304 - val_accuracy: 0.6992\n",
      "Epoch 407/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4978 - accuracy: 0.7373 - val_loss: 0.5303 - val_accuracy: 0.6992\n",
      "Epoch 408/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4975 - accuracy: 0.7373 - val_loss: 0.5300 - val_accuracy: 0.6992\n",
      "Epoch 409/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4974 - accuracy: 0.7373 - val_loss: 0.5298 - val_accuracy: 0.6992\n",
      "Epoch 410/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4973 - accuracy: 0.7393 - val_loss: 0.5296 - val_accuracy: 0.6911\n",
      "Epoch 411/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4972 - accuracy: 0.7352 - val_loss: 0.5294 - val_accuracy: 0.6911\n",
      "Epoch 412/1000\n",
      "491/491 [==============================] - 0s 89us/step - loss: 0.4962 - accuracy: 0.7393 - val_loss: 0.5293 - val_accuracy: 0.6911\n",
      "Epoch 413/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4965 - accuracy: 0.7373 - val_loss: 0.5291 - val_accuracy: 0.6911\n",
      "Epoch 414/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4961 - accuracy: 0.7393 - val_loss: 0.5289 - val_accuracy: 0.6911\n",
      "Epoch 415/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4957 - accuracy: 0.7413 - val_loss: 0.5287 - val_accuracy: 0.6911\n",
      "Epoch 416/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4955 - accuracy: 0.7413 - val_loss: 0.5286 - val_accuracy: 0.6911\n",
      "Epoch 417/1000\n",
      "491/491 [==============================] - 0s 100us/step - loss: 0.4954 - accuracy: 0.7434 - val_loss: 0.5284 - val_accuracy: 0.6911\n",
      "Epoch 418/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4952 - accuracy: 0.7352 - val_loss: 0.5282 - val_accuracy: 0.6992\n",
      "Epoch 419/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4943 - accuracy: 0.7413 - val_loss: 0.5280 - val_accuracy: 0.6911\n",
      "Epoch 420/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4940 - accuracy: 0.7413 - val_loss: 0.5278 - val_accuracy: 0.6911\n",
      "Epoch 421/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4938 - accuracy: 0.7413 - val_loss: 0.5276 - val_accuracy: 0.6911\n",
      "Epoch 422/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4934 - accuracy: 0.7413 - val_loss: 0.5275 - val_accuracy: 0.6992\n",
      "Epoch 423/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4933 - accuracy: 0.7475 - val_loss: 0.5273 - val_accuracy: 0.6992\n",
      "Epoch 424/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4931 - accuracy: 0.7475 - val_loss: 0.5271 - val_accuracy: 0.6992\n",
      "Epoch 425/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4927 - accuracy: 0.7454 - val_loss: 0.5269 - val_accuracy: 0.6992\n",
      "Epoch 426/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4929 - accuracy: 0.7454 - val_loss: 0.5267 - val_accuracy: 0.6911\n",
      "Epoch 427/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.4924 - accuracy: 0.7475 - val_loss: 0.5265 - val_accuracy: 0.6992\n",
      "Epoch 428/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.71 - 0s 67us/step - loss: 0.4920 - accuracy: 0.7454 - val_loss: 0.5264 - val_accuracy: 0.6992\n",
      "Epoch 429/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4918 - accuracy: 0.7413 - val_loss: 0.5262 - val_accuracy: 0.6992\n",
      "Epoch 430/1000\n",
      "491/491 [==============================] - 0s 107us/step - loss: 0.4915 - accuracy: 0.7434 - val_loss: 0.5260 - val_accuracy: 0.6992\n",
      "Epoch 431/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4913 - accuracy: 0.7454 - val_loss: 0.5258 - val_accuracy: 0.6992\n",
      "Epoch 432/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4907 - accuracy: 0.7454 - val_loss: 0.5257 - val_accuracy: 0.6992\n",
      "Epoch 433/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4908 - accuracy: 0.7454 - val_loss: 0.5255 - val_accuracy: 0.6911\n",
      "Epoch 434/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4904 - accuracy: 0.7434 - val_loss: 0.5253 - val_accuracy: 0.6992\n",
      "Epoch 435/1000\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.4901 - accuracy: 0.7454 - val_loss: 0.5251 - val_accuracy: 0.6992\n",
      "Epoch 436/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4897 - accuracy: 0.7495 - val_loss: 0.5250 - val_accuracy: 0.6992\n",
      "Epoch 437/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4899 - accuracy: 0.7495 - val_loss: 0.5248 - val_accuracy: 0.6992\n",
      "Epoch 438/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4900 - accuracy: 0.7495 - val_loss: 0.5246 - val_accuracy: 0.6992\n",
      "Epoch 439/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4891 - accuracy: 0.7536 - val_loss: 0.5245 - val_accuracy: 0.7154\n",
      "Epoch 440/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4886 - accuracy: 0.7536 - val_loss: 0.5243 - val_accuracy: 0.7073\n",
      "Epoch 441/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4885 - accuracy: 0.7495 - val_loss: 0.5242 - val_accuracy: 0.7073\n",
      "Epoch 442/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4885 - accuracy: 0.7454 - val_loss: 0.5241 - val_accuracy: 0.7154\n",
      "Epoch 443/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.64 - 0s 63us/step - loss: 0.4879 - accuracy: 0.7495 - val_loss: 0.5239 - val_accuracy: 0.7073\n",
      "Epoch 444/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4875 - accuracy: 0.7536 - val_loss: 0.5237 - val_accuracy: 0.7073\n",
      "Epoch 445/1000\n",
      "491/491 [==============================] - 0s 95us/step - loss: 0.4873 - accuracy: 0.7536 - val_loss: 0.5235 - val_accuracy: 0.7154\n",
      "Epoch 446/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4875 - accuracy: 0.7556 - val_loss: 0.5234 - val_accuracy: 0.7073\n",
      "Epoch 447/1000\n",
      "491/491 [==============================] - 0s 95us/step - loss: 0.4866 - accuracy: 0.7495 - val_loss: 0.5232 - val_accuracy: 0.7073\n",
      "Epoch 448/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4870 - accuracy: 0.7536 - val_loss: 0.5230 - val_accuracy: 0.7073\n",
      "Epoch 449/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4863 - accuracy: 0.7475 - val_loss: 0.5229 - val_accuracy: 0.7073\n",
      "Epoch 450/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4862 - accuracy: 0.7495 - val_loss: 0.5227 - val_accuracy: 0.7073\n",
      "Epoch 451/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4859 - accuracy: 0.7536 - val_loss: 0.5226 - val_accuracy: 0.7073\n",
      "Epoch 452/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4854 - accuracy: 0.7536 - val_loss: 0.5225 - val_accuracy: 0.7073\n",
      "Epoch 453/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4853 - accuracy: 0.7515 - val_loss: 0.5223 - val_accuracy: 0.7073\n",
      "Epoch 454/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4852 - accuracy: 0.7515 - val_loss: 0.5222 - val_accuracy: 0.7073\n",
      "Epoch 455/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4846 - accuracy: 0.7536 - val_loss: 0.5220 - val_accuracy: 0.7073\n",
      "Epoch 456/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4844 - accuracy: 0.7536 - val_loss: 0.5219 - val_accuracy: 0.7073\n",
      "Epoch 457/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.4849 - accuracy: 0.7515 - val_loss: 0.5218 - val_accuracy: 0.7073\n",
      "Epoch 458/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4840 - accuracy: 0.7495 - val_loss: 0.5217 - val_accuracy: 0.7073\n",
      "Epoch 459/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.4837 - accuracy: 0.7515 - val_loss: 0.5214 - val_accuracy: 0.7073\n",
      "Epoch 460/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4836 - accuracy: 0.7597 - val_loss: 0.5212 - val_accuracy: 0.7073\n",
      "Epoch 461/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4832 - accuracy: 0.7536 - val_loss: 0.5210 - val_accuracy: 0.7073\n",
      "Epoch 462/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4831 - accuracy: 0.7556 - val_loss: 0.5210 - val_accuracy: 0.7073\n",
      "Epoch 463/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4828 - accuracy: 0.7556 - val_loss: 0.5208 - val_accuracy: 0.7073\n",
      "Epoch 464/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4827 - accuracy: 0.7556 - val_loss: 0.5208 - val_accuracy: 0.7073\n",
      "Epoch 465/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4822 - accuracy: 0.7576 - val_loss: 0.5206 - val_accuracy: 0.7073\n",
      "Epoch 466/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4821 - accuracy: 0.7556 - val_loss: 0.5204 - val_accuracy: 0.7073\n",
      "Epoch 467/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4816 - accuracy: 0.7556 - val_loss: 0.5204 - val_accuracy: 0.7073\n",
      "Epoch 468/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4817 - accuracy: 0.7556 - val_loss: 0.5203 - val_accuracy: 0.7073\n",
      "Epoch 469/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4813 - accuracy: 0.7576 - val_loss: 0.5202 - val_accuracy: 0.7073\n",
      "Epoch 470/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4813 - accuracy: 0.7576 - val_loss: 0.5200 - val_accuracy: 0.7073\n",
      "Epoch 471/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4812 - accuracy: 0.7556 - val_loss: 0.5198 - val_accuracy: 0.7073\n",
      "Epoch 472/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4809 - accuracy: 0.7576 - val_loss: 0.5198 - val_accuracy: 0.7073\n",
      "Epoch 473/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4805 - accuracy: 0.7597 - val_loss: 0.5195 - val_accuracy: 0.7073\n",
      "Epoch 474/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4805 - accuracy: 0.7637 - val_loss: 0.5192 - val_accuracy: 0.7073\n",
      "Epoch 475/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4799 - accuracy: 0.7576 - val_loss: 0.5192 - val_accuracy: 0.7073\n",
      "Epoch 476/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4795 - accuracy: 0.7576 - val_loss: 0.5190 - val_accuracy: 0.7073\n",
      "Epoch 477/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4794 - accuracy: 0.7576 - val_loss: 0.5189 - val_accuracy: 0.7073\n",
      "Epoch 478/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4800 - accuracy: 0.7576 - val_loss: 0.5188 - val_accuracy: 0.7073\n",
      "Epoch 479/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4791 - accuracy: 0.7617 - val_loss: 0.5186 - val_accuracy: 0.7154\n",
      "Epoch 480/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4788 - accuracy: 0.7576 - val_loss: 0.5185 - val_accuracy: 0.7073\n",
      "Epoch 481/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4787 - accuracy: 0.7576 - val_loss: 0.5184 - val_accuracy: 0.7154\n",
      "Epoch 482/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4787 - accuracy: 0.7597 - val_loss: 0.5185 - val_accuracy: 0.7073\n",
      "Epoch 483/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4780 - accuracy: 0.7597 - val_loss: 0.5183 - val_accuracy: 0.7073\n",
      "Epoch 484/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4779 - accuracy: 0.7576 - val_loss: 0.5184 - val_accuracy: 0.7073\n",
      "Epoch 485/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4776 - accuracy: 0.7678 - val_loss: 0.5180 - val_accuracy: 0.7154\n",
      "Epoch 486/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4773 - accuracy: 0.7658 - val_loss: 0.5179 - val_accuracy: 0.7154\n",
      "Epoch 487/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4772 - accuracy: 0.7617 - val_loss: 0.5178 - val_accuracy: 0.7154\n",
      "Epoch 488/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4771 - accuracy: 0.7637 - val_loss: 0.5176 - val_accuracy: 0.7073\n",
      "Epoch 489/1000\n",
      "491/491 [==============================] - 0s 104us/step - loss: 0.4770 - accuracy: 0.7678 - val_loss: 0.5177 - val_accuracy: 0.7154\n",
      "Epoch 490/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4768 - accuracy: 0.7658 - val_loss: 0.5174 - val_accuracy: 0.7154\n",
      "Epoch 491/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4769 - accuracy: 0.7617 - val_loss: 0.5173 - val_accuracy: 0.7154\n",
      "Epoch 492/1000\n",
      "491/491 [==============================] - 0s 119us/step - loss: 0.4767 - accuracy: 0.7658 - val_loss: 0.5172 - val_accuracy: 0.7154\n",
      "Epoch 493/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4757 - accuracy: 0.7678 - val_loss: 0.5170 - val_accuracy: 0.7073\n",
      "Epoch 494/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4756 - accuracy: 0.7658 - val_loss: 0.5169 - val_accuracy: 0.7073\n",
      "Epoch 495/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4757 - accuracy: 0.7658 - val_loss: 0.5169 - val_accuracy: 0.7073\n",
      "Epoch 496/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4752 - accuracy: 0.7617 - val_loss: 0.5167 - val_accuracy: 0.7073\n",
      "Epoch 497/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4748 - accuracy: 0.7658 - val_loss: 0.5167 - val_accuracy: 0.7073\n",
      "Epoch 498/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4747 - accuracy: 0.7678 - val_loss: 0.5166 - val_accuracy: 0.7073\n",
      "Epoch 499/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4748 - accuracy: 0.7678 - val_loss: 0.5164 - val_accuracy: 0.7073\n",
      "Epoch 500/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4742 - accuracy: 0.7658 - val_loss: 0.5164 - val_accuracy: 0.7073\n",
      "Epoch 501/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4741 - accuracy: 0.7699 - val_loss: 0.5163 - val_accuracy: 0.7073\n",
      "Epoch 502/1000\n",
      "491/491 [==============================] - 0s 116us/step - loss: 0.4738 - accuracy: 0.7658 - val_loss: 0.5162 - val_accuracy: 0.7073\n",
      "Epoch 503/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4737 - accuracy: 0.7678 - val_loss: 0.5161 - val_accuracy: 0.7073\n",
      "Epoch 504/1000\n",
      "491/491 [==============================] - 0s 110us/step - loss: 0.4735 - accuracy: 0.7658 - val_loss: 0.5160 - val_accuracy: 0.7073\n",
      "Epoch 505/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4733 - accuracy: 0.7719 - val_loss: 0.5158 - val_accuracy: 0.7073\n",
      "Epoch 506/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4733 - accuracy: 0.7658 - val_loss: 0.5157 - val_accuracy: 0.7073\n",
      "Epoch 507/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4727 - accuracy: 0.7739 - val_loss: 0.5156 - val_accuracy: 0.7073\n",
      "Epoch 508/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4725 - accuracy: 0.7678 - val_loss: 0.5155 - val_accuracy: 0.7073\n",
      "Epoch 509/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4723 - accuracy: 0.7658 - val_loss: 0.5155 - val_accuracy: 0.7073\n",
      "Epoch 510/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4725 - accuracy: 0.7719 - val_loss: 0.5153 - val_accuracy: 0.7073\n",
      "Epoch 511/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4720 - accuracy: 0.7699 - val_loss: 0.5154 - val_accuracy: 0.7073\n",
      "Epoch 512/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4719 - accuracy: 0.7719 - val_loss: 0.5152 - val_accuracy: 0.7073\n",
      "Epoch 513/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4714 - accuracy: 0.7678 - val_loss: 0.5151 - val_accuracy: 0.7073\n",
      "Epoch 514/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4715 - accuracy: 0.7699 - val_loss: 0.5150 - val_accuracy: 0.7073\n",
      "Epoch 515/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.4711 - accuracy: 0.7678 - val_loss: 0.5148 - val_accuracy: 0.7073\n",
      "Epoch 516/1000\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.4716 - accuracy: 0.7699 - val_loss: 0.5147 - val_accuracy: 0.7154\n",
      "Epoch 517/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4710 - accuracy: 0.7658 - val_loss: 0.5146 - val_accuracy: 0.7154\n",
      "Epoch 518/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4707 - accuracy: 0.7719 - val_loss: 0.5145 - val_accuracy: 0.7073\n",
      "Epoch 519/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4706 - accuracy: 0.7699 - val_loss: 0.5144 - val_accuracy: 0.7073\n",
      "Epoch 520/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4706 - accuracy: 0.7719 - val_loss: 0.5144 - val_accuracy: 0.7073\n",
      "Epoch 521/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4706 - accuracy: 0.7678 - val_loss: 0.5143 - val_accuracy: 0.7154\n",
      "Epoch 522/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4704 - accuracy: 0.7719 - val_loss: 0.5143 - val_accuracy: 0.7073\n",
      "Epoch 523/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4699 - accuracy: 0.7699 - val_loss: 0.5144 - val_accuracy: 0.7154\n",
      "Epoch 524/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7073\n",
      "Epoch 525/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4697 - accuracy: 0.7719 - val_loss: 0.5141 - val_accuracy: 0.7073\n",
      "Epoch 526/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4692 - accuracy: 0.7699 - val_loss: 0.5141 - val_accuracy: 0.7073\n",
      "Epoch 527/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4691 - accuracy: 0.7719 - val_loss: 0.5140 - val_accuracy: 0.7073\n",
      "Epoch 528/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4692 - accuracy: 0.7719 - val_loss: 0.5142 - val_accuracy: 0.7154\n",
      "Epoch 529/1000\n",
      "491/491 [==============================] - 0s 104us/step - loss: 0.4696 - accuracy: 0.7658 - val_loss: 0.5142 - val_accuracy: 0.7236\n",
      "Epoch 530/1000\n",
      "491/491 [==============================] - 0s 98us/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7154\n",
      "Epoch 531/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7073\n",
      "Epoch 532/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4680 - accuracy: 0.7780 - val_loss: 0.5133 - val_accuracy: 0.7154\n",
      "Epoch 533/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.5133 - val_accuracy: 0.7154\n",
      "Epoch 534/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7154\n",
      "Epoch 535/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4676 - accuracy: 0.7739 - val_loss: 0.5132 - val_accuracy: 0.7154\n",
      "Epoch 536/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4678 - accuracy: 0.7800 - val_loss: 0.5131 - val_accuracy: 0.6992\n",
      "Epoch 537/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.6992\n",
      "Epoch 538/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4671 - accuracy: 0.7739 - val_loss: 0.5129 - val_accuracy: 0.7073\n",
      "Epoch 539/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4670 - accuracy: 0.7780 - val_loss: 0.5129 - val_accuracy: 0.7073\n",
      "Epoch 540/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4666 - accuracy: 0.7780 - val_loss: 0.5130 - val_accuracy: 0.7154\n",
      "Epoch 541/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4668 - accuracy: 0.7800 - val_loss: 0.5131 - val_accuracy: 0.7154\n",
      "Epoch 542/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4667 - accuracy: 0.7739 - val_loss: 0.5127 - val_accuracy: 0.7154\n",
      "Epoch 543/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4659 - accuracy: 0.7739 - val_loss: 0.5126 - val_accuracy: 0.7154\n",
      "Epoch 544/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7154\n",
      "Epoch 545/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4659 - accuracy: 0.7780 - val_loss: 0.5125 - val_accuracy: 0.7154\n",
      "Epoch 546/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4657 - accuracy: 0.7780 - val_loss: 0.5125 - val_accuracy: 0.7154\n",
      "Epoch 547/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4652 - accuracy: 0.7800 - val_loss: 0.5124 - val_accuracy: 0.7073\n",
      "Epoch 548/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4652 - accuracy: 0.7780 - val_loss: 0.5123 - val_accuracy: 0.7073\n",
      "Epoch 549/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7154\n",
      "Epoch 550/1000\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7154\n",
      "Epoch 551/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4648 - accuracy: 0.7739 - val_loss: 0.5121 - val_accuracy: 0.7154\n",
      "Epoch 552/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5120 - val_accuracy: 0.7236\n",
      "Epoch 553/1000\n",
      "491/491 [==============================] - 0s 98us/step - loss: 0.4644 - accuracy: 0.7780 - val_loss: 0.5120 - val_accuracy: 0.7154\n",
      "Epoch 554/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7154\n",
      "Epoch 555/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4641 - accuracy: 0.7780 - val_loss: 0.5119 - val_accuracy: 0.7154\n",
      "Epoch 556/1000\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7236\n",
      "Epoch 557/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4638 - accuracy: 0.7780 - val_loss: 0.5117 - val_accuracy: 0.7236\n",
      "Epoch 558/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7236\n",
      "Epoch 559/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7154\n",
      "Epoch 560/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7154\n",
      "Epoch 561/1000\n",
      "491/491 [==============================] - 0s 89us/step - loss: 0.4629 - accuracy: 0.7780 - val_loss: 0.5114 - val_accuracy: 0.7236\n",
      "Epoch 562/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4630 - accuracy: 0.7739 - val_loss: 0.5115 - val_accuracy: 0.7236\n",
      "Epoch 563/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4629 - accuracy: 0.7800 - val_loss: 0.5113 - val_accuracy: 0.7317\n",
      "Epoch 564/1000\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7317\n",
      "Epoch 565/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4631 - accuracy: 0.7780 - val_loss: 0.5110 - val_accuracy: 0.7154\n",
      "Epoch 566/1000\n",
      "491/491 [==============================] - 0s 108us/step - loss: 0.4632 - accuracy: 0.7800 - val_loss: 0.5110 - val_accuracy: 0.7073\n",
      "Epoch 567/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7154\n",
      "Epoch 568/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4639 - accuracy: 0.7780 - val_loss: 0.5107 - val_accuracy: 0.7236\n",
      "Epoch 569/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7154\n",
      "Epoch 570/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7236\n",
      "Epoch 571/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4616 - accuracy: 0.7800 - val_loss: 0.5106 - val_accuracy: 0.7236\n",
      "Epoch 572/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7236\n",
      "Epoch 573/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4618 - accuracy: 0.7800 - val_loss: 0.5104 - val_accuracy: 0.7236\n",
      "Epoch 574/1000\n",
      "491/491 [==============================] - 0s 120us/step - loss: 0.4610 - accuracy: 0.7780 - val_loss: 0.5104 - val_accuracy: 0.7236\n",
      "Epoch 575/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4610 - accuracy: 0.7800 - val_loss: 0.5104 - val_accuracy: 0.7236\n",
      "Epoch 576/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4609 - accuracy: 0.7800 - val_loss: 0.5104 - val_accuracy: 0.7154\n",
      "Epoch 577/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4612 - accuracy: 0.7780 - val_loss: 0.5102 - val_accuracy: 0.7236\n",
      "Epoch 578/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4606 - accuracy: 0.7780 - val_loss: 0.5102 - val_accuracy: 0.7236\n",
      "Epoch 579/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4603 - accuracy: 0.7780 - val_loss: 0.5102 - val_accuracy: 0.7236\n",
      "Epoch 580/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4603 - accuracy: 0.7780 - val_loss: 0.5101 - val_accuracy: 0.7236\n",
      "Epoch 581/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4607 - accuracy: 0.7780 - val_loss: 0.5109 - val_accuracy: 0.7154\n",
      "Epoch 582/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4607 - accuracy: 0.7800 - val_loss: 0.5102 - val_accuracy: 0.7317\n",
      "Epoch 583/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4599 - accuracy: 0.7821 - val_loss: 0.5098 - val_accuracy: 0.7236\n",
      "Epoch 584/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4599 - accuracy: 0.7821 - val_loss: 0.5099 - val_accuracy: 0.7236\n",
      "Epoch 585/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4597 - accuracy: 0.7800 - val_loss: 0.5097 - val_accuracy: 0.7236\n",
      "Epoch 586/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.5096 - val_accuracy: 0.7236\n",
      "Epoch 587/1000\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.4596 - accuracy: 0.7739 - val_loss: 0.5097 - val_accuracy: 0.7236\n",
      "Epoch 588/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4596 - accuracy: 0.7800 - val_loss: 0.5097 - val_accuracy: 0.7236\n",
      "Epoch 589/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4587 - accuracy: 0.7800 - val_loss: 0.5095 - val_accuracy: 0.7236\n",
      "Epoch 590/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4590 - accuracy: 0.7800 - val_loss: 0.5095 - val_accuracy: 0.7236\n",
      "Epoch 591/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4590 - accuracy: 0.7780 - val_loss: 0.5095 - val_accuracy: 0.7236\n",
      "Epoch 592/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4587 - accuracy: 0.7780 - val_loss: 0.5094 - val_accuracy: 0.7236\n",
      "Epoch 593/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4584 - accuracy: 0.7780 - val_loss: 0.5093 - val_accuracy: 0.7236\n",
      "Epoch 594/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4582 - accuracy: 0.7800 - val_loss: 0.5092 - val_accuracy: 0.7236\n",
      "Epoch 595/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7236\n",
      "Epoch 596/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4582 - accuracy: 0.7780 - val_loss: 0.5091 - val_accuracy: 0.7236\n",
      "Epoch 597/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4587 - accuracy: 0.7800 - val_loss: 0.5090 - val_accuracy: 0.7236\n",
      "Epoch 598/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4578 - accuracy: 0.7821 - val_loss: 0.5090 - val_accuracy: 0.7236\n",
      "Epoch 599/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4580 - accuracy: 0.7800 - val_loss: 0.5090 - val_accuracy: 0.7236\n",
      "Epoch 600/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4572 - accuracy: 0.7800 - val_loss: 0.5090 - val_accuracy: 0.7236\n",
      "Epoch 601/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4574 - accuracy: 0.7821 - val_loss: 0.5089 - val_accuracy: 0.7236\n",
      "Epoch 602/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4571 - accuracy: 0.7800 - val_loss: 0.5089 - val_accuracy: 0.7236\n",
      "Epoch 603/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4570 - accuracy: 0.7800 - val_loss: 0.5088 - val_accuracy: 0.7236\n",
      "Epoch 604/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4571 - accuracy: 0.7800 - val_loss: 0.5088 - val_accuracy: 0.7236\n",
      "Epoch 605/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4574 - accuracy: 0.7841 - val_loss: 0.5087 - val_accuracy: 0.7236\n",
      "Epoch 606/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4566 - accuracy: 0.7800 - val_loss: 0.5086 - val_accuracy: 0.7236\n",
      "Epoch 607/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4570 - accuracy: 0.7800 - val_loss: 0.5084 - val_accuracy: 0.7236\n",
      "Epoch 608/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4565 - accuracy: 0.7841 - val_loss: 0.5083 - val_accuracy: 0.7236\n",
      "Epoch 609/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7236\n",
      "Epoch 610/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4561 - accuracy: 0.7841 - val_loss: 0.5083 - val_accuracy: 0.7236\n",
      "Epoch 611/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4559 - accuracy: 0.7780 - val_loss: 0.5082 - val_accuracy: 0.7236\n",
      "Epoch 612/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4559 - accuracy: 0.7821 - val_loss: 0.5081 - val_accuracy: 0.7236\n",
      "Epoch 613/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4563 - accuracy: 0.7800 - val_loss: 0.5082 - val_accuracy: 0.7236\n",
      "Epoch 614/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4559 - accuracy: 0.7841 - val_loss: 0.5081 - val_accuracy: 0.7236\n",
      "Epoch 615/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4554 - accuracy: 0.7841 - val_loss: 0.5080 - val_accuracy: 0.7236\n",
      "Epoch 616/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4555 - accuracy: 0.7841 - val_loss: 0.5080 - val_accuracy: 0.7317\n",
      "Epoch 617/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4552 - accuracy: 0.7821 - val_loss: 0.5079 - val_accuracy: 0.7317\n",
      "Epoch 618/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4549 - accuracy: 0.7821 - val_loss: 0.5078 - val_accuracy: 0.7317\n",
      "Epoch 619/1000\n",
      "491/491 [==============================] - 0s 103us/step - loss: 0.4552 - accuracy: 0.7821 - val_loss: 0.5078 - val_accuracy: 0.7317\n",
      "Epoch 620/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4557 - accuracy: 0.7780 - val_loss: 0.5077 - val_accuracy: 0.7236\n",
      "Epoch 621/1000\n",
      "491/491 [==============================] - 0s 128us/step - loss: 0.4549 - accuracy: 0.7841 - val_loss: 0.5077 - val_accuracy: 0.7317\n",
      "Epoch 622/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4548 - accuracy: 0.7862 - val_loss: 0.5077 - val_accuracy: 0.7317\n",
      "Epoch 623/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.5077 - val_accuracy: 0.7317\n",
      "Epoch 624/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4547 - accuracy: 0.7841 - val_loss: 0.5076 - val_accuracy: 0.7236\n",
      "Epoch 625/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4543 - accuracy: 0.7841 - val_loss: 0.5074 - val_accuracy: 0.7236\n",
      "Epoch 626/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4540 - accuracy: 0.7862 - val_loss: 0.5074 - val_accuracy: 0.7317\n",
      "Epoch 627/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4543 - accuracy: 0.7821 - val_loss: 0.5078 - val_accuracy: 0.7236\n",
      "Epoch 628/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4538 - accuracy: 0.7862 - val_loss: 0.5075 - val_accuracy: 0.7317\n",
      "Epoch 629/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4546 - accuracy: 0.7841 - val_loss: 0.5073 - val_accuracy: 0.7236\n",
      "Epoch 630/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4536 - accuracy: 0.7841 - val_loss: 0.5073 - val_accuracy: 0.7236\n",
      "Epoch 631/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4534 - accuracy: 0.7841 - val_loss: 0.5072 - val_accuracy: 0.7236\n",
      "Epoch 632/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7317\n",
      "Epoch 633/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4535 - accuracy: 0.7841 - val_loss: 0.5070 - val_accuracy: 0.7317\n",
      "Epoch 634/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4541 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7317\n",
      "Epoch 635/1000\n",
      "491/491 [==============================] - 0s 124us/step - loss: 0.4536 - accuracy: 0.7862 - val_loss: 0.5071 - val_accuracy: 0.7317\n",
      "Epoch 636/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4534 - accuracy: 0.7841 - val_loss: 0.5074 - val_accuracy: 0.7317\n",
      "Epoch 637/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4528 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7317\n",
      "Epoch 638/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4527 - accuracy: 0.7862 - val_loss: 0.5068 - val_accuracy: 0.7317\n",
      "Epoch 639/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4529 - accuracy: 0.7841 - val_loss: 0.5069 - val_accuracy: 0.7236\n",
      "Epoch 640/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4523 - accuracy: 0.7862 - val_loss: 0.5069 - val_accuracy: 0.7236\n",
      "Epoch 641/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4526 - accuracy: 0.7841 - val_loss: 0.5068 - val_accuracy: 0.7236\n",
      "Epoch 642/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4523 - accuracy: 0.7821 - val_loss: 0.5067 - val_accuracy: 0.7317\n",
      "Epoch 643/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4519 - accuracy: 0.7841 - val_loss: 0.5067 - val_accuracy: 0.7317\n",
      "Epoch 644/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4522 - accuracy: 0.7841 - val_loss: 0.5068 - val_accuracy: 0.7317\n",
      "Epoch 645/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4517 - accuracy: 0.7841 - val_loss: 0.5068 - val_accuracy: 0.7236\n",
      "Epoch 646/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4518 - accuracy: 0.7862 - val_loss: 0.5067 - val_accuracy: 0.7317\n",
      "Epoch 647/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4516 - accuracy: 0.7862 - val_loss: 0.5066 - val_accuracy: 0.7317\n",
      "Epoch 648/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4512 - accuracy: 0.7821 - val_loss: 0.5067 - val_accuracy: 0.7317\n",
      "Epoch 649/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4517 - accuracy: 0.7841 - val_loss: 0.5067 - val_accuracy: 0.7317\n",
      "Epoch 650/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4516 - accuracy: 0.7841 - val_loss: 0.5065 - val_accuracy: 0.7317\n",
      "Epoch 651/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4512 - accuracy: 0.7841 - val_loss: 0.5064 - val_accuracy: 0.7317\n",
      "Epoch 652/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4511 - accuracy: 0.7841 - val_loss: 0.5063 - val_accuracy: 0.7317\n",
      "Epoch 653/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4511 - accuracy: 0.7862 - val_loss: 0.5063 - val_accuracy: 0.7317\n",
      "Epoch 654/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4507 - accuracy: 0.7862 - val_loss: 0.5063 - val_accuracy: 0.7317\n",
      "Epoch 655/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4505 - accuracy: 0.7841 - val_loss: 0.5063 - val_accuracy: 0.7398\n",
      "Epoch 656/1000\n",
      "491/491 [==============================] - 0s 106us/step - loss: 0.4509 - accuracy: 0.7841 - val_loss: 0.5063 - val_accuracy: 0.7398\n",
      "Epoch 657/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4503 - accuracy: 0.7821 - val_loss: 0.5064 - val_accuracy: 0.7317\n",
      "Epoch 658/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4507 - accuracy: 0.7841 - val_loss: 0.5062 - val_accuracy: 0.7398\n",
      "Epoch 659/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4498 - accuracy: 0.7862 - val_loss: 0.5061 - val_accuracy: 0.7398\n",
      "Epoch 660/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4503 - accuracy: 0.7841 - val_loss: 0.5061 - val_accuracy: 0.7317\n",
      "Epoch 661/1000\n",
      "491/491 [==============================] - 0s 97us/step - loss: 0.4503 - accuracy: 0.7780 - val_loss: 0.5063 - val_accuracy: 0.7317\n",
      "Epoch 662/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4501 - accuracy: 0.7821 - val_loss: 0.5059 - val_accuracy: 0.7317\n",
      "Epoch 663/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4507 - accuracy: 0.7800 - val_loss: 0.5060 - val_accuracy: 0.7317\n",
      "Epoch 664/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4496 - accuracy: 0.7800 - val_loss: 0.5060 - val_accuracy: 0.7398\n",
      "Epoch 665/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4495 - accuracy: 0.7862 - val_loss: 0.5060 - val_accuracy: 0.7398\n",
      "Epoch 666/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.71 - 0s 59us/step - loss: 0.4498 - accuracy: 0.7821 - val_loss: 0.5060 - val_accuracy: 0.7398\n",
      "Epoch 667/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4491 - accuracy: 0.7862 - val_loss: 0.5058 - val_accuracy: 0.7317\n",
      "Epoch 668/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4492 - accuracy: 0.7780 - val_loss: 0.5060 - val_accuracy: 0.7398\n",
      "Epoch 669/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4494 - accuracy: 0.7841 - val_loss: 0.5061 - val_accuracy: 0.7317\n",
      "Epoch 670/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4494 - accuracy: 0.7841 - val_loss: 0.5060 - val_accuracy: 0.7317\n",
      "Epoch 671/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4494 - accuracy: 0.7821 - val_loss: 0.5060 - val_accuracy: 0.7317\n",
      "Epoch 672/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4489 - accuracy: 0.7841 - val_loss: 0.5058 - val_accuracy: 0.7398\n",
      "Epoch 673/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4485 - accuracy: 0.7821 - val_loss: 0.5057 - val_accuracy: 0.7398\n",
      "Epoch 674/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4484 - accuracy: 0.7841 - val_loss: 0.5059 - val_accuracy: 0.7317\n",
      "Epoch 675/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4486 - accuracy: 0.7841 - val_loss: 0.5058 - val_accuracy: 0.7398\n",
      "Epoch 676/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4483 - accuracy: 0.7862 - val_loss: 0.5058 - val_accuracy: 0.7398\n",
      "Epoch 677/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4491 - accuracy: 0.7841 - val_loss: 0.5058 - val_accuracy: 0.7398\n",
      "Epoch 678/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4484 - accuracy: 0.7841 - val_loss: 0.5057 - val_accuracy: 0.7398\n",
      "Epoch 679/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4480 - accuracy: 0.7862 - val_loss: 0.5056 - val_accuracy: 0.7398\n",
      "Epoch 680/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4479 - accuracy: 0.7841 - val_loss: 0.5054 - val_accuracy: 0.7317\n",
      "Epoch 681/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4483 - accuracy: 0.7780 - val_loss: 0.5055 - val_accuracy: 0.7398\n",
      "Epoch 682/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4478 - accuracy: 0.7821 - val_loss: 0.5055 - val_accuracy: 0.7398\n",
      "Epoch 683/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4475 - accuracy: 0.7821 - val_loss: 0.5055 - val_accuracy: 0.7398\n",
      "Epoch 684/1000\n",
      "491/491 [==============================] - 0s 108us/step - loss: 0.4478 - accuracy: 0.7862 - val_loss: 0.5054 - val_accuracy: 0.7398\n",
      "Epoch 685/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4483 - accuracy: 0.7841 - val_loss: 0.5054 - val_accuracy: 0.7398\n",
      "Epoch 686/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.5054 - val_accuracy: 0.7398\n",
      "Epoch 687/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4472 - accuracy: 0.7841 - val_loss: 0.5053 - val_accuracy: 0.7398\n",
      "Epoch 688/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4474 - accuracy: 0.7862 - val_loss: 0.5053 - val_accuracy: 0.7398\n",
      "Epoch 689/1000\n",
      "491/491 [==============================] - 0s 91us/step - loss: 0.4472 - accuracy: 0.7821 - val_loss: 0.5052 - val_accuracy: 0.7398\n",
      "Epoch 690/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4474 - accuracy: 0.7821 - val_loss: 0.5052 - val_accuracy: 0.7398\n",
      "Epoch 691/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4479 - accuracy: 0.7821 - val_loss: 0.5054 - val_accuracy: 0.7480\n",
      "Epoch 692/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4467 - accuracy: 0.7821 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
      "Epoch 693/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4471 - accuracy: 0.7821 - val_loss: 0.5055 - val_accuracy: 0.7398\n",
      "Epoch 694/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4470 - accuracy: 0.7862 - val_loss: 0.5051 - val_accuracy: 0.7398\n",
      "Epoch 695/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4467 - accuracy: 0.7841 - val_loss: 0.5051 - val_accuracy: 0.7398\n",
      "Epoch 696/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4470 - accuracy: 0.7862 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
      "Epoch 697/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4472 - accuracy: 0.7821 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
      "Epoch 698/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4462 - accuracy: 0.7821 - val_loss: 0.5048 - val_accuracy: 0.7480\n",
      "Epoch 699/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4469 - accuracy: 0.7800 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
      "Epoch 700/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4462 - accuracy: 0.7862 - val_loss: 0.5051 - val_accuracy: 0.7480\n",
      "Epoch 701/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4465 - accuracy: 0.7800 - val_loss: 0.5050 - val_accuracy: 0.7398\n",
      "Epoch 702/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4460 - accuracy: 0.7841 - val_loss: 0.5049 - val_accuracy: 0.7398\n",
      "Epoch 703/1000\n",
      "491/491 [==============================] - 0s 117us/step - loss: 0.4458 - accuracy: 0.7862 - val_loss: 0.5048 - val_accuracy: 0.7398\n",
      "Epoch 704/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4464 - accuracy: 0.7821 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
      "Epoch 705/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4455 - accuracy: 0.7841 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
      "Epoch 706/1000\n",
      "491/491 [==============================] - 0s 128us/step - loss: 0.4457 - accuracy: 0.7841 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
      "Epoch 707/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4460 - accuracy: 0.7841 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
      "Epoch 708/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4458 - accuracy: 0.7800 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
      "Epoch 709/1000\n",
      "491/491 [==============================] - 0s 140us/step - loss: 0.4455 - accuracy: 0.7841 - val_loss: 0.5047 - val_accuracy: 0.7398\n",
      "Epoch 710/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4460 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
      "Epoch 711/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4453 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
      "Epoch 712/1000\n",
      "491/491 [==============================] - 0s 118us/step - loss: 0.4451 - accuracy: 0.7800 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
      "Epoch 713/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4449 - accuracy: 0.7902 - val_loss: 0.5050 - val_accuracy: 0.7317\n",
      "Epoch 714/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.4457 - accuracy: 0.7800 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
      "Epoch 715/1000\n",
      "491/491 [==============================] - 0s 134us/step - loss: 0.4451 - accuracy: 0.7800 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
      "Epoch 716/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4452 - accuracy: 0.7821 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
      "Epoch 717/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4456 - accuracy: 0.7821 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
      "Epoch 718/1000\n",
      "491/491 [==============================] - 0s 110us/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7480\n",
      "Epoch 719/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
      "Epoch 720/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7398\n",
      "Epoch 721/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4446 - accuracy: 0.7821 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
      "Epoch 722/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4441 - accuracy: 0.7841 - val_loss: 0.5045 - val_accuracy: 0.7398\n",
      "Epoch 723/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4446 - accuracy: 0.7862 - val_loss: 0.5049 - val_accuracy: 0.7154\n",
      "Epoch 724/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4449 - accuracy: 0.7821 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
      "Epoch 725/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4442 - accuracy: 0.7841 - val_loss: 0.5044 - val_accuracy: 0.7480\n",
      "Epoch 726/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4439 - accuracy: 0.7862 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
      "Epoch 727/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4439 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
      "Epoch 728/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4441 - accuracy: 0.7821 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
      "Epoch 729/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4440 - accuracy: 0.7862 - val_loss: 0.5040 - val_accuracy: 0.7561\n",
      "Epoch 730/1000\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4442 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
      "Epoch 731/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4448 - accuracy: 0.7800 - val_loss: 0.5038 - val_accuracy: 0.7561\n",
      "Epoch 732/1000\n",
      "491/491 [==============================] - 0s 89us/step - loss: 0.4439 - accuracy: 0.7862 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
      "Epoch 733/1000\n",
      "491/491 [==============================] - 0s 104us/step - loss: 0.4439 - accuracy: 0.7862 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
      "Epoch 734/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
      "Epoch 735/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4434 - accuracy: 0.7862 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
      "Epoch 736/1000\n",
      "491/491 [==============================] - 0s 91us/step - loss: 0.4432 - accuracy: 0.7862 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
      "Epoch 737/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4429 - accuracy: 0.7862 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
      "Epoch 738/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4435 - accuracy: 0.7841 - val_loss: 0.5036 - val_accuracy: 0.7480\n",
      "Epoch 739/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4436 - accuracy: 0.7821 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
      "Epoch 740/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4429 - accuracy: 0.7862 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
      "Epoch 741/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4429 - accuracy: 0.7821 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
      "Epoch 742/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4433 - accuracy: 0.7902 - val_loss: 0.5034 - val_accuracy: 0.7480\n",
      "Epoch 743/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4429 - accuracy: 0.7862 - val_loss: 0.5038 - val_accuracy: 0.7398\n",
      "Epoch 744/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4430 - accuracy: 0.7862 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
      "Epoch 745/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7480\n",
      "Epoch 746/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7317\n",
      "Epoch 747/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4433 - accuracy: 0.7821 - val_loss: 0.5031 - val_accuracy: 0.7480\n",
      "Epoch 748/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4424 - accuracy: 0.7821 - val_loss: 0.5031 - val_accuracy: 0.7480\n",
      "Epoch 749/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4422 - accuracy: 0.7841 - val_loss: 0.5029 - val_accuracy: 0.7561\n",
      "Epoch 750/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4426 - accuracy: 0.7841 - val_loss: 0.5033 - val_accuracy: 0.7642\n",
      "Epoch 751/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4426 - accuracy: 0.7841 - val_loss: 0.5032 - val_accuracy: 0.7480\n",
      "Epoch 752/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
      "Epoch 753/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4424 - accuracy: 0.7862 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
      "Epoch 754/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4424 - accuracy: 0.7902 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
      "Epoch 755/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4417 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7398\n",
      "Epoch 756/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4419 - accuracy: 0.7841 - val_loss: 0.5031 - val_accuracy: 0.7561\n",
      "Epoch 757/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4418 - accuracy: 0.7862 - val_loss: 0.5030 - val_accuracy: 0.7561\n",
      "Epoch 758/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4417 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7398\n",
      "Epoch 759/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7398\n",
      "Epoch 760/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4414 - accuracy: 0.7821 - val_loss: 0.5029 - val_accuracy: 0.7561\n",
      "Epoch 761/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4415 - accuracy: 0.7923 - val_loss: 0.5028 - val_accuracy: 0.7561\n",
      "Epoch 762/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7561\n",
      "Epoch 763/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7561\n",
      "Epoch 764/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4413 - accuracy: 0.7862 - val_loss: 0.5031 - val_accuracy: 0.7480\n",
      "Epoch 765/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4412 - accuracy: 0.7862 - val_loss: 0.5029 - val_accuracy: 0.7642\n",
      "Epoch 766/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4413 - accuracy: 0.7923 - val_loss: 0.5027 - val_accuracy: 0.7561\n",
      "Epoch 767/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7561\n",
      "Epoch 768/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4416 - accuracy: 0.7862 - val_loss: 0.5027 - val_accuracy: 0.7561\n",
      "Epoch 769/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4408 - accuracy: 0.7862 - val_loss: 0.5027 - val_accuracy: 0.7561\n",
      "Epoch 770/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4405 - accuracy: 0.7902 - val_loss: 0.5027 - val_accuracy: 0.7561\n",
      "Epoch 771/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4408 - accuracy: 0.7923 - val_loss: 0.5029 - val_accuracy: 0.7398\n",
      "Epoch 772/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4407 - accuracy: 0.7862 - val_loss: 0.5028 - val_accuracy: 0.7561\n",
      "Epoch 773/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7561\n",
      "Epoch 774/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4416 - accuracy: 0.7862 - val_loss: 0.5026 - val_accuracy: 0.7480\n",
      "Epoch 775/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7398\n",
      "Epoch 776/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4407 - accuracy: 0.7841 - val_loss: 0.5026 - val_accuracy: 0.7398\n",
      "Epoch 777/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4404 - accuracy: 0.7862 - val_loss: 0.5025 - val_accuracy: 0.7561\n",
      "Epoch 778/1000\n",
      "491/491 [==============================] - 0s 128us/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7398\n",
      "Epoch 779/1000\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.4412 - accuracy: 0.7943 - val_loss: 0.5025 - val_accuracy: 0.7642\n",
      "Epoch 780/1000\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.4405 - accuracy: 0.7862 - val_loss: 0.5026 - val_accuracy: 0.7642\n",
      "Epoch 781/1000\n",
      "491/491 [==============================] - 0s 102us/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7480\n",
      "Epoch 782/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7398\n",
      "Epoch 783/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7398\n",
      "Epoch 784/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4403 - accuracy: 0.7902 - val_loss: 0.5025 - val_accuracy: 0.7561\n",
      "Epoch 785/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7642\n",
      "Epoch 786/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4401 - accuracy: 0.7902 - val_loss: 0.5026 - val_accuracy: 0.7561\n",
      "Epoch 787/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4403 - accuracy: 0.7923 - val_loss: 0.5024 - val_accuracy: 0.7642\n",
      "Epoch 788/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4401 - accuracy: 0.7943 - val_loss: 0.5027 - val_accuracy: 0.7398\n",
      "Epoch 789/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4396 - accuracy: 0.7862 - val_loss: 0.5024 - val_accuracy: 0.7398\n",
      "Epoch 790/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4398 - accuracy: 0.7902 - val_loss: 0.5022 - val_accuracy: 0.7398\n",
      "Epoch 791/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4397 - accuracy: 0.7923 - val_loss: 0.5022 - val_accuracy: 0.7642\n",
      "Epoch 792/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4392 - accuracy: 0.7943 - val_loss: 0.5022 - val_accuracy: 0.7642\n",
      "Epoch 793/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7642\n",
      "Epoch 794/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4396 - accuracy: 0.7923 - val_loss: 0.5022 - val_accuracy: 0.7398\n",
      "Epoch 795/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4398 - accuracy: 0.7943 - val_loss: 0.5025 - val_accuracy: 0.7398\n",
      "Epoch 796/1000\n",
      "491/491 [==============================] - 0s 93us/step - loss: 0.4392 - accuracy: 0.7902 - val_loss: 0.5023 - val_accuracy: 0.7398\n",
      "Epoch 797/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7561\n",
      "Epoch 798/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4404 - accuracy: 0.7943 - val_loss: 0.5021 - val_accuracy: 0.7398\n",
      "Epoch 799/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4396 - accuracy: 0.7923 - val_loss: 0.5022 - val_accuracy: 0.7398\n",
      "Epoch 800/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4391 - accuracy: 0.7963 - val_loss: 0.5025 - val_accuracy: 0.7480\n",
      "Epoch 801/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7398\n",
      "Epoch 802/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4392 - accuracy: 0.7923 - val_loss: 0.5022 - val_accuracy: 0.7398\n",
      "Epoch 803/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4390 - accuracy: 0.7902 - val_loss: 0.5025 - val_accuracy: 0.7480\n",
      "Epoch 804/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4390 - accuracy: 0.7923 - val_loss: 0.5023 - val_accuracy: 0.7480\n",
      "Epoch 805/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4392 - accuracy: 0.7902 - val_loss: 0.5019 - val_accuracy: 0.7480\n",
      "Epoch 806/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7642\n",
      "Epoch 807/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4394 - accuracy: 0.7923 - val_loss: 0.5024 - val_accuracy: 0.7480\n",
      "Epoch 808/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4390 - accuracy: 0.7862 - val_loss: 0.5028 - val_accuracy: 0.7398\n",
      "Epoch 809/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7480\n",
      "Epoch 810/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4381 - accuracy: 0.7902 - val_loss: 0.5025 - val_accuracy: 0.7480\n",
      "Epoch 811/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7561\n",
      "Epoch 812/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7480\n",
      "Epoch 813/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4384 - accuracy: 0.7923 - val_loss: 0.5020 - val_accuracy: 0.7480\n",
      "Epoch 814/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4381 - accuracy: 0.7923 - val_loss: 0.5020 - val_accuracy: 0.7480\n",
      "Epoch 815/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4383 - accuracy: 0.7902 - val_loss: 0.5025 - val_accuracy: 0.7480\n",
      "Epoch 816/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4378 - accuracy: 0.7902 - val_loss: 0.5019 - val_accuracy: 0.7561\n",
      "Epoch 817/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7480\n",
      "Epoch 818/1000\n",
      "491/491 [==============================] - 0s 70us/step - loss: 0.4378 - accuracy: 0.7902 - val_loss: 0.5021 - val_accuracy: 0.7561\n",
      "Epoch 819/1000\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.4378 - accuracy: 0.7902 - val_loss: 0.5019 - val_accuracy: 0.7480\n",
      "Epoch 820/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4376 - accuracy: 0.7902 - val_loss: 0.5021 - val_accuracy: 0.7480\n",
      "Epoch 821/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4382 - accuracy: 0.7923 - val_loss: 0.5026 - val_accuracy: 0.7480\n",
      "Epoch 822/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4379 - accuracy: 0.7943 - val_loss: 0.5020 - val_accuracy: 0.7561\n",
      "Epoch 823/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4380 - accuracy: 0.7923 - val_loss: 0.5016 - val_accuracy: 0.7480\n",
      "Epoch 824/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4381 - accuracy: 0.7943 - val_loss: 0.5016 - val_accuracy: 0.7561\n",
      "Epoch 825/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4385 - accuracy: 0.7923 - val_loss: 0.5015 - val_accuracy: 0.7642\n",
      "Epoch 826/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7480\n",
      "Epoch 827/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4383 - accuracy: 0.7902 - val_loss: 0.5016 - val_accuracy: 0.7480\n",
      "Epoch 828/1000\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.4373 - accuracy: 0.7923 - val_loss: 0.5024 - val_accuracy: 0.7480\n",
      "Epoch 829/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4377 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7561\n",
      "Epoch 830/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4380 - accuracy: 0.7963 - val_loss: 0.5020 - val_accuracy: 0.7561\n",
      "Epoch 831/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4376 - accuracy: 0.7963 - val_loss: 0.5017 - val_accuracy: 0.7561\n",
      "Epoch 832/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4376 - accuracy: 0.7963 - val_loss: 0.5016 - val_accuracy: 0.7561\n",
      "Epoch 833/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4376 - accuracy: 0.7963 - val_loss: 0.5013 - val_accuracy: 0.7398\n",
      "Epoch 834/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4370 - accuracy: 0.7963 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 835/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4377 - accuracy: 0.7943 - val_loss: 0.5017 - val_accuracy: 0.7642\n",
      "Epoch 836/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4370 - accuracy: 0.7923 - val_loss: 0.5016 - val_accuracy: 0.7642\n",
      "Epoch 837/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4383 - accuracy: 0.7902 - val_loss: 0.5015 - val_accuracy: 0.7642\n",
      "Epoch 838/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4365 - accuracy: 0.7923 - val_loss: 0.5018 - val_accuracy: 0.7642\n",
      "Epoch 839/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4369 - accuracy: 0.7963 - val_loss: 0.5018 - val_accuracy: 0.7561\n",
      "Epoch 840/1000\n",
      "491/491 [==============================] - 0s 48us/step - loss: 0.4368 - accuracy: 0.7943 - val_loss: 0.5020 - val_accuracy: 0.7642\n",
      "Epoch 841/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4365 - accuracy: 0.7902 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 842/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4378 - accuracy: 0.7943 - val_loss: 0.5018 - val_accuracy: 0.7642\n",
      "Epoch 843/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4372 - accuracy: 0.7862 - val_loss: 0.5024 - val_accuracy: 0.7561\n",
      "Epoch 844/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4366 - accuracy: 0.7902 - val_loss: 0.5015 - val_accuracy: 0.7642\n",
      "Epoch 845/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4371 - accuracy: 0.7902 - val_loss: 0.5013 - val_accuracy: 0.7561\n",
      "Epoch 846/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4361 - accuracy: 0.7963 - val_loss: 0.5017 - val_accuracy: 0.7724\n",
      "Epoch 847/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4363 - accuracy: 0.7984 - val_loss: 0.5017 - val_accuracy: 0.7724\n",
      "Epoch 848/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4363 - accuracy: 0.7963 - val_loss: 0.5016 - val_accuracy: 0.7724\n",
      "Epoch 849/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4363 - accuracy: 0.7923 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
      "Epoch 850/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4367 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 851/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4365 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 852/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4368 - accuracy: 0.7963 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
      "Epoch 853/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4365 - accuracy: 0.7923 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 854/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4369 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7480\n",
      "Epoch 855/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4371 - accuracy: 0.7923 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
      "Epoch 856/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4359 - accuracy: 0.7984 - val_loss: 0.5013 - val_accuracy: 0.7724\n",
      "Epoch 857/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4360 - accuracy: 0.7943 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
      "Epoch 858/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4358 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 859/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4366 - accuracy: 0.7963 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
      "Epoch 860/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4355 - accuracy: 0.7963 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 861/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4356 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7724\n",
      "Epoch 862/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4359 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
      "Epoch 863/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
      "Epoch 864/1000\n",
      "491/491 [==============================] - 0s 91us/step - loss: 0.4360 - accuracy: 0.7923 - val_loss: 0.5016 - val_accuracy: 0.7561\n",
      "Epoch 865/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4362 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 866/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4359 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
      "Epoch 867/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4358 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 868/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4354 - accuracy: 0.7943 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
      "Epoch 869/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
      "Epoch 870/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4359 - accuracy: 0.7943 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 871/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4357 - accuracy: 0.7923 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 872/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 873/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4360 - accuracy: 0.8024 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 874/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.4357 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 875/1000\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4347 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
      "Epoch 876/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4355 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
      "Epoch 877/1000\n",
      "491/491 [==============================] - 0s 116us/step - loss: 0.4362 - accuracy: 0.7963 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 878/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4354 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 879/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4357 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 880/1000\n",
      "491/491 [==============================] - 0s 95us/step - loss: 0.4350 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 881/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4352 - accuracy: 0.7984 - val_loss: 0.5013 - val_accuracy: 0.7724\n",
      "Epoch 882/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4347 - accuracy: 0.7963 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
      "Epoch 883/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4345 - accuracy: 0.7923 - val_loss: 0.5013 - val_accuracy: 0.7561\n",
      "Epoch 884/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4347 - accuracy: 0.7943 - val_loss: 0.5013 - val_accuracy: 0.7561\n",
      "Epoch 885/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4353 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
      "Epoch 886/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4341 - accuracy: 0.7943 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
      "Epoch 887/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4345 - accuracy: 0.7963 - val_loss: 0.5015 - val_accuracy: 0.7724\n",
      "Epoch 888/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4345 - accuracy: 0.7923 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 889/1000\n",
      "491/491 [==============================] - 0s 48us/step - loss: 0.4344 - accuracy: 0.7943 - val_loss: 0.5017 - val_accuracy: 0.7724\n",
      "Epoch 890/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4348 - accuracy: 0.7923 - val_loss: 0.5017 - val_accuracy: 0.7724\n",
      "Epoch 891/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4339 - accuracy: 0.7943 - val_loss: 0.5016 - val_accuracy: 0.7642\n",
      "Epoch 892/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4341 - accuracy: 0.7963 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 893/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7923 - val_loss: 0.5017 - val_accuracy: 0.7642\n",
      "Epoch 894/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4345 - accuracy: 0.7963 - val_loss: 0.5013 - val_accuracy: 0.7561\n",
      "Epoch 895/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4339 - accuracy: 0.7943 - val_loss: 0.5015 - val_accuracy: 0.7724\n",
      "Epoch 896/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4346 - accuracy: 0.7923 - val_loss: 0.5016 - val_accuracy: 0.7642\n",
      "Epoch 897/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4340 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 898/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4341 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
      "Epoch 899/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4340 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 900/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4336 - accuracy: 0.7943 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 901/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4341 - accuracy: 0.7963 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 902/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4345 - accuracy: 0.8004 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 903/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4347 - accuracy: 0.7943 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 904/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4336 - accuracy: 0.7963 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 905/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4339 - accuracy: 0.7923 - val_loss: 0.5018 - val_accuracy: 0.7642\n",
      "Epoch 906/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4335 - accuracy: 0.7984 - val_loss: 0.5016 - val_accuracy: 0.7642\n",
      "Epoch 907/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4339 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
      "Epoch 908/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4337 - accuracy: 0.7984 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 909/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4335 - accuracy: 0.7902 - val_loss: 0.5013 - val_accuracy: 0.7561\n",
      "Epoch 910/1000\n",
      "491/491 [==============================] - 0s 104us/step - loss: 0.4336 - accuracy: 0.7943 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 911/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4333 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 912/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4332 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 913/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4332 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 914/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4336 - accuracy: 0.7923 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
      "Epoch 915/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4332 - accuracy: 0.7943 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 916/1000\n",
      "491/491 [==============================] - 0s 89us/step - loss: 0.4336 - accuracy: 0.7963 - val_loss: 0.5019 - val_accuracy: 0.7561\n",
      "Epoch 917/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4336 - accuracy: 0.7923 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 918/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4341 - accuracy: 0.7902 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 919/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4328 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 920/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 921/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4331 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 922/1000\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.4330 - accuracy: 0.7984 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 923/1000\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4330 - accuracy: 0.7943 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 924/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4330 - accuracy: 0.7943 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 925/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 926/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4334 - accuracy: 0.7963 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
      "Epoch 927/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4325 - accuracy: 0.7984 - val_loss: 0.5007 - val_accuracy: 0.7561\n",
      "Epoch 928/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4334 - accuracy: 0.7984 - val_loss: 0.5007 - val_accuracy: 0.7561\n",
      "Epoch 929/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4338 - accuracy: 0.7902 - val_loss: 0.5008 - val_accuracy: 0.7642\n",
      "Epoch 930/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4331 - accuracy: 0.7943 - val_loss: 0.5008 - val_accuracy: 0.7561\n",
      "Epoch 931/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 932/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4330 - accuracy: 0.7963 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 933/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4336 - accuracy: 0.7902 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 934/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4330 - accuracy: 0.7902 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 935/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
      "Epoch 936/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4326 - accuracy: 0.7963 - val_loss: 0.5007 - val_accuracy: 0.7561\n",
      "Epoch 937/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4329 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
      "Epoch 938/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.4328 - accuracy: 0.7902 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 939/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4329 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 940/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4325 - accuracy: 0.7943 - val_loss: 0.5007 - val_accuracy: 0.7642\n",
      "Epoch 941/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4321 - accuracy: 0.7943 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 942/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4319 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
      "Epoch 943/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4321 - accuracy: 0.7963 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 944/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4326 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 945/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4327 - accuracy: 0.7943 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 946/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4319 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 947/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4325 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 948/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4320 - accuracy: 0.7943 - val_loss: 0.5012 - val_accuracy: 0.7480\n",
      "Epoch 949/1000\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4318 - accuracy: 0.7984 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 950/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4321 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
      "Epoch 951/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4332 - accuracy: 0.7984 - val_loss: 0.5016 - val_accuracy: 0.7642\n",
      "Epoch 952/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4323 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7480\n",
      "Epoch 953/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4325 - accuracy: 0.7984 - val_loss: 0.5015 - val_accuracy: 0.7642\n",
      "Epoch 954/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.4320 - accuracy: 0.7963 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 955/1000\n",
      "491/491 [==============================] - 0s 51us/step - loss: 0.4327 - accuracy: 0.7902 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 956/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4317 - accuracy: 0.7963 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 957/1000\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.4318 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 958/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4314 - accuracy: 0.7943 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 959/1000\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.4314 - accuracy: 0.7943 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 960/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4317 - accuracy: 0.7923 - val_loss: 0.5012 - val_accuracy: 0.7480\n",
      "Epoch 961/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4315 - accuracy: 0.8004 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 962/1000\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4317 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 963/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4320 - accuracy: 0.7862 - val_loss: 0.5007 - val_accuracy: 0.7642\n",
      "Epoch 964/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4324 - accuracy: 0.7984 - val_loss: 0.5008 - val_accuracy: 0.7642\n",
      "Epoch 965/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 966/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4314 - accuracy: 0.8004 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 967/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4311 - accuracy: 0.7984 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 968/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4317 - accuracy: 0.8004 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 969/1000\n",
      "491/491 [==============================] - 0s 116us/step - loss: 0.4311 - accuracy: 0.7963 - val_loss: 0.5008 - val_accuracy: 0.7561\n",
      "Epoch 970/1000\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4315 - accuracy: 0.7984 - val_loss: 0.5009 - val_accuracy: 0.7480\n",
      "Epoch 971/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4315 - accuracy: 0.8004 - val_loss: 0.5010 - val_accuracy: 0.7480\n",
      "Epoch 972/1000\n",
      "491/491 [==============================] - 0s 106us/step - loss: 0.4326 - accuracy: 0.7943 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 973/1000\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.4329 - accuracy: 0.7923 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 974/1000\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.4312 - accuracy: 0.7984 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 975/1000\n",
      "491/491 [==============================] - 0s 85us/step - loss: 0.4314 - accuracy: 0.7923 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
      "Epoch 976/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4316 - accuracy: 0.7963 - val_loss: 0.5012 - val_accuracy: 0.7480\n",
      "Epoch 977/1000\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4308 - accuracy: 0.8045 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
      "Epoch 978/1000\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.4311 - accuracy: 0.7963 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 979/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4307 - accuracy: 0.8004 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 980/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4308 - accuracy: 0.8004 - val_loss: 0.5009 - val_accuracy: 0.7480\n",
      "Epoch 981/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4312 - accuracy: 0.7963 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
      "Epoch 982/1000\n",
      "491/491 [==============================] - 0s 106us/step - loss: 0.4311 - accuracy: 0.7984 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
      "Epoch 983/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4308 - accuracy: 0.8045 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
      "Epoch 984/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4315 - accuracy: 0.7943 - val_loss: 0.5015 - val_accuracy: 0.7642\n",
      "Epoch 985/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4310 - accuracy: 0.7963 - val_loss: 0.5011 - val_accuracy: 0.7480\n",
      "Epoch 986/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4308 - accuracy: 0.7984 - val_loss: 0.5006 - val_accuracy: 0.7642\n",
      "Epoch 987/1000\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.5006 - val_accuracy: 0.7642\n",
      "Epoch 988/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4319 - accuracy: 0.7984 - val_loss: 0.5008 - val_accuracy: 0.7642\n",
      "Epoch 989/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.4305 - accuracy: 0.8004 - val_loss: 0.5008 - val_accuracy: 0.7642\n",
      "Epoch 990/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.4315 - accuracy: 0.7943 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
      "Epoch 991/1000\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.4310 - accuracy: 0.7984 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 992/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.4307 - accuracy: 0.7963 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
      "Epoch 993/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4301 - accuracy: 0.7984 - val_loss: 0.5014 - val_accuracy: 0.7480\n",
      "Epoch 994/1000\n",
      "491/491 [==============================] - 0s 49us/step - loss: 0.4305 - accuracy: 0.7984 - val_loss: 0.5021 - val_accuracy: 0.7642\n",
      "Epoch 995/1000\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4312 - accuracy: 0.8045 - val_loss: 0.5020 - val_accuracy: 0.7642\n",
      "Epoch 996/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4309 - accuracy: 0.8004 - val_loss: 0.5012 - val_accuracy: 0.7480\n",
      "Epoch 997/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4310 - accuracy: 0.7984 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 998/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.4305 - accuracy: 0.7984 - val_loss: 0.5013 - val_accuracy: 0.7480\n",
      "Epoch 999/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4303 - accuracy: 0.7984 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
      "Epoch 1000/1000\n",
      "491/491 [==============================] - 0s 47us/step - loss: 0.4307 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "          batch_size=57, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the training loss and the validation loss to see if the model is overfitting\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the training accuracy and the validation accuracy to see if the model is overfitting\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([0.6,None])\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction & print the actual values\n",
    "prediction = model.predict(X_test)\n",
    "prediction  = [1 if y>=0.5 else 0 for y in prediction] #Threshold\n",
    "print(prediction)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84       398\n",
      "         1.0       0.74      0.62      0.68       216\n",
      "\n",
      "    accuracy                           0.79       614\n",
      "   macro avg       0.78      0.75      0.76       614\n",
      "weighted avg       0.79      0.79      0.79       614\n",
      "\n",
      "Confusion Matrix: \n",
      " [[351  47]\n",
      " [ 82 134]]\n",
      "\n",
      "Accuracy:  0.7899022801302932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "pred = model.predict(X_train)\n",
    "pred  = [1 if y>=0.5 else 0 for y in pred] #Threshold\n",
    "print(classification_report(y_train ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82       102\n",
      "         1.0       0.65      0.65      0.65        52\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.74      0.74      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[84 18]\n",
      " [18 34]]\n",
      "\n",
      "Accuracy:  0.7662337662337663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "pred = model.predict(X_test)\n",
    "pred  = [1 if y>=0.5 else 0 for y in pred] #Threshold\n",
    "print(classification_report(y_test ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7662337422370911"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
